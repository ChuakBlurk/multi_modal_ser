{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5449328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b3d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_RATE = 16000\n",
    "y1, y2, y3, y4, x1, x2, x3, x4 = (128, 352, 128, 352, 68, 292, 428, 652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce833c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pims\n",
    "video = pims.Video('Ses01F_impro01.avi')\n",
    "frame = video[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f87f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_video_array(vid):\n",
    "    sess_id = vid[4]\n",
    "    video_path = \"E:/datasets/IEMOCAP_full_release.tar/IEMOCAP_full_release/IEMOCAP_full_release/Session{}/dialog/avi/DivX/{}.avi\".format(sess_id,vid)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    success=True\n",
    "    frame_list = []\n",
    "    while success:\n",
    "        success, frame=cap.read()\n",
    "        frame_list.append(frame)\n",
    "\n",
    "    video_array = np.array(frame_list[:-1])\n",
    "    del frame_list\n",
    "    return video_array, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0abfd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_arr2vid(arr, output_path, fps):\n",
    "    print(arr.shape)\n",
    "    out = cv2.VideoWriter(output_path, \n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                          fps, (arr.shape[2], arr.shape[1]))\n",
    "    for i in range(arr.shape[0]):\n",
    "        data = arr[i, :, :, :]\n",
    "        out.write(data)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e985437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video_array(vid, output_dir, fps):\n",
    "    sess_id = vid[4]\n",
    "    video_path = \"E:/datasets/IEMOCAP_full_release.tar/IEMOCAP_full_release/IEMOCAP_full_release/Session{}/dialog/avi/DivX/{}.avi\".format(sess_id,vid)\n",
    "    video = pims.Video(video_path)\n",
    "    df = pd.read_excel('E:/datasets/preprocessed/extractionmap/cut_extractionmap{}.xlsx'.format(sess_id), sheet_name=vid)\n",
    "    df[\"viframe\"] = np.floor(df[\"iframe\"]*fps/AUDIO_RATE).astype(int)\n",
    "    df[\"vfframe\"] = np.ceil(df[\"fframe\"]*fps/AUDIO_RATE).astype(int)\n",
    "    \n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    width = height = 88\n",
    "    for index, row in df.iterrows():\n",
    "        center = None\n",
    "        varr = np.asarray(video[row[\"viframe\"]:row[\"vfframe\"]])\n",
    "        if row[\"speaker\"] == \"L\":\n",
    "            arr = varr[:, \n",
    "                       y1:y2, \n",
    "                       x1:x2, :]\n",
    "        elif row[\"speaker\"] == \"R\":\n",
    "            arr = varr[:, \n",
    "                       y3:y4, \n",
    "                       x3:x4, :]\n",
    "            \n",
    "        img_stack_sm = []\n",
    "        for idx in range(arr.shape[0]):\n",
    "            img = arr[idx, :, :, :]\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray)\n",
    "            \n",
    "            if len(faces) != 0:\n",
    "                x,y,w,h = faces[0]\n",
    "                xc = int(round((2*x+w)/2))\n",
    "                yc = int(round((2*y+h)/2))\n",
    "                center = [xc, yc]\n",
    "            else:\n",
    "                if idx == 0:\n",
    "                    center = [gray.shape[1]//2, gray.shape[0]//2]\n",
    "                \n",
    "            face = gray[center[1]-int(height/2):center[1]+int(height/2), \n",
    "                        center[0]-int(width/2):center[0]+int(width/2)]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_GRAY2BGR)\n",
    "            face = cv2.resize(face, (88, 88), interpolation=cv2.INTER_AREA)\n",
    "            img_stack_sm.append(face)\n",
    "            \n",
    "        img_stack_sm = np.array(img_stack_sm)\n",
    "        save_path = os.path.join(output_dir, \"{}\".format(row[\"smp_id\"]))\n",
    "        save_arr2vid(img_stack_sm, save_path+\".mp4\", fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5086ed1a",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e6d6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"E:/university/FYT/repos/multi_modal_ser\")\n",
    "from utils.dataset import MMSERDataset\n",
    "mmser_ds = torch.load(\"E:/datasets/preprocessed/dataset/mmser_ds.pt\")\n",
    "df_ = mmser_ds.df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36f20f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_[\"fn\"] = df_[\"smp_id\"].apply(lambda x: x[:-5])\n",
    "smp_id_list = df_[\"fn\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "daabf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_id_list = [i for i in smp_id_list if i.startswith(\"Ses01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d94a08c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses01F_impro01\n",
      "(60, 88, 88, 3)\n",
      "(88, 88, 88, 3)\n",
      "(42, 88, 88, 3)\n",
      "(113, 88, 88, 3)\n",
      "(95, 88, 88, 3)\n",
      "(87, 88, 88, 3)\n",
      "(46, 88, 88, 3)\n",
      "(104, 88, 88, 3)\n",
      "(137, 88, 88, 3)\n",
      "(122, 88, 88, 3)\n",
      "(86, 88, 88, 3)\n",
      "(245, 88, 88, 3)\n",
      "(140, 88, 88, 3)\n",
      "(174, 88, 88, 3)\n",
      "(169, 88, 88, 3)\n",
      "(188, 88, 88, 3)\n",
      "(81, 88, 88, 3)\n",
      "(133, 88, 88, 3)\n",
      "(124, 88, 88, 3)\n",
      "(225, 88, 88, 3)\n",
      "(89, 88, 88, 3)\n",
      "(295, 88, 88, 3)\n",
      "(134, 88, 88, 3)\n",
      "(83, 88, 88, 3)\n",
      "(218, 88, 88, 3)\n",
      "(101, 88, 88, 3)\n",
      "(86, 88, 88, 3)\n",
      "(153, 88, 88, 3)\n",
      "(182, 88, 88, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|████                                                                                                               | 1/28 [00:55<24:48, 55.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 88, 88, 3)\n",
      "Ses01F_impro02\n",
      "(280, 88, 88, 3)\n",
      "(91, 88, 88, 3)\n",
      "(89, 88, 88, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                               | 1/28 [01:01<27:39, 61.45s/it]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vid \u001b[38;5;129;01min\u001b[39;00m tqdm(smp_id_list):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(vid)\n\u001b[1;32m----> 6\u001b[0m     save_video_array(vid,\n\u001b[0;32m      7\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:/datasets/preprocessed/face_roi/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(vid\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m      8\u001b[0m                  fps)\n",
      "Cell \u001b[1;32mIn[37], line 41\u001b[0m, in \u001b[0;36msave_video_array\u001b[1;34m(vid, output_dir, fps)\u001b[0m\n\u001b[0;32m     37\u001b[0m         center \u001b[38;5;241m=\u001b[39m [gray\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, gray\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     39\u001b[0m face \u001b[38;5;241m=\u001b[39m gray[center[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mint\u001b[39m(height\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m):center[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mint\u001b[39m(height\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), \n\u001b[0;32m     40\u001b[0m             center[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mint\u001b[39m(width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m):center[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mint\u001b[39m(width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)]\n\u001b[1;32m---> 41\u001b[0m face \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(face, cv2\u001b[38;5;241m.\u001b[39mCOLOR_GRAY2BGR)\n\u001b[0;32m     42\u001b[0m face \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face, (\u001b[38;5;241m88\u001b[39m, \u001b[38;5;241m88\u001b[39m), interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_AREA)\n\u001b[0;32m     43\u001b[0m img_stack_sm\u001b[38;5;241m.\u001b[39mappend(face)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm \n",
    "\n",
    "# fps=30\n",
    "# for vid in tqdm(smp_id_list):\n",
    "#     print(vid)\n",
    "#     save_video_array(vid,\n",
    "#                  \"E:/datasets/preprocessed/face_roi/{}\".format(vid.split(\"_\")[0][:-1]),\n",
    "#                  fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58392da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc74218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_video_array(smp_id_list[0],\n",
    "#                  \"E:/datasets/preprocessed/face_roi/{}\".format(smp_id_list[0].split(\"_\")[0][:-1]),\n",
    "#                  30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25af8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "ser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
