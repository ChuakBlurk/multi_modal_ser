{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "445b6748-52e1-4ba0-b190-8d4b58042068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: accelerate in d:\\anaconda\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in d:\\anaconda\\lib\\site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in d:\\anaconda\\lib\\site-packages (from accelerate) (0.17.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from huggingface-hub->accelerate) (2023.3.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: datasets in d:\\anaconda\\lib\\site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\anaconda\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in d:\\anaconda\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\anaconda\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in d:\\anaconda\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in d:\\anaconda\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in d:\\anaconda\\lib\\site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: aiohttp in d:\\anaconda\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in d:\\anaconda\\lib\\site-packages (from datasets) (0.17.2)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\anaconda\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Collecting wandb\n",
      "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/1c/5e/0362fa88679852c7fd3ac85ee5bd949426c4a51a61379010d4089be6d7ac/wandb-0.15.12-py3-none-any.whl.metadata\n",
      "  Downloading wandb-0.15.12-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in d:\\anaconda\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for GitPython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/8a/7e/20f7e45878b5aed34320fbeeae8f78acc806e7bd708d00b1c6e64b016f5b/GitPython-3.1.37-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.37-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in d:\\anaconda\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/63/25/d22e1e152e4eac10d39d9132d7b5f1ea4bdfa0b9a1d65fc606a7b90aeefb/sentry_sdk-1.32.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in d:\\anaconda\\lib\\site-packages (from wandb) (6.0)\n",
      "Collecting pathtools (from wandb)\n",
      "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting setproctitle (from wandb)\n",
      "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/7e/ba/f6da9ba74e8c2c662e932b27a01025c1bee2846222f6a2e87a69c259772f/setproctitle-1.3.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in d:\\anaconda\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,<5,>=3.19.0 from https://files.pythonhosted.org/packages/c2/59/f89c04923d68595d359f4cd7adbbdf5e5d791257945f8873d88b2fd1f979/protobuf-4.24.4-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.24.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in d:\\anaconda\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.1 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.1 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
      "   ---------------------------------------- 0.0/190.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 190.0/190.0 kB ? eta 0:00:00\n",
      "Downloading protobuf-4.24.4-cp310-abi3-win_amd64.whl (430 kB)\n",
      "   ---------------------------------------- 0.0/430.5 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 399.4/430.5 kB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 430.5/430.5 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/241.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 241.0/241.0 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-win_amd64.whl (11 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8801 sha256=4c33cf1f42abdabdca8156c973d43c7ddfdfb9027836baa8e02ff80d09d94d3c\n",
      "  Stored in directory: c:\\users\\legion\\appdata\\local\\pip\\cache\\wheels\\ea\\b7\\8b\\84e94095ea418b9442f5abeba4ca7b0ad52d3fe7b69d6238a6\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.37 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 protobuf-4.24.4 sentry-sdk-1.32.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.15.12\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install transformers\n",
    "!pip install accelerate -U\n",
    "!pip install datasets\n",
    "!pip install scikit-learn\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06e5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoFeatureExtractor, WhisperForAudioClassification, Trainer, TrainingArguments\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "# sys.path.append(\"E:/university/FYT/repos/multi_modal_ser\")\n",
    "sys.path.append(\"/home/multi_modal_ser\")\n",
    "from utils.dataset import MMSERDataset\n",
    "from datasets import load_metric\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from processed_dataset import ProcessedDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13fd87b",
   "metadata": {},
   "source": [
    "### HUBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de5fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/hubert-large-ls960-ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2690485b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion ID:  [2. 1. 3. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 5531/5531 [01:22<00:00, 66.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# mmser_ds = torch.load(\"E:/datasets/preprocessed/dataset/mmser_ds.pt\")\n",
    "mmser_ds = torch.load(\"/home/mmser_ds.pt\")\n",
    "print(\"Emotion ID: \", mmser_ds.df_[\"emotion_id\"].unique())\n",
    "processed_ds = ProcessedDataset(mmser_ds, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82abced",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea498c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, HubertModel, AutoModel\n",
    "encoder_model = AutoModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15de142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_classifier import CustomClassifier\n",
    "model = CustomClassifier(MODEL_NAME, mmser_ds.df_[\"emotion_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a0dce8",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6a61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_ = processed_ds.base_ds.df_\n",
    "sess_dict = meta_df_.groupby(\"session\").groups\n",
    "all_indices = set(meta_df_.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a87265",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_ds = {}\n",
    "for sess in sess_dict:\n",
    "    sess_ds[sess+\"_train\"] = Subset(processed_ds, \n",
    "                                    indices=list(all_indices-set(sess_dict[sess])))\n",
    "    sess_ds[sess+\"_test\"] = Subset(processed_ds, \n",
    "                                    indices=sess_dict[sess])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a102497",
   "metadata": {},
   "source": [
    "### Set SESS_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031b4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ds(sess_id):\n",
    "    train_size = int(len(sess_ds[sess_id+\"_train\"])*0.75)\n",
    "    val_size = len(sess_ds[sess_id+\"_train\"])-train_size\n",
    "    train_set, val_set = torch.utils.data.random_split(sess_ds[sess_id+\"_train\"], [train_size, val_size])\n",
    "    test_set = sess_ds[sess_id+\"_test\"]\n",
    "\n",
    "    print(\"Train Samples:\", len(train_set))\n",
    "    print(\"Val Samples:\", len(val_set))\n",
    "    print(\"Test Samples:\", len(test_set))\n",
    "    \n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1ed21-6b96-4eb2-9a57-19dfe67abf35",
   "metadata": {},
   "source": [
    "##### Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3760e071-5f5a-4272-9c32-df3157dd6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.projector.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9fa2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_trainer import CustomTrainer, compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47eaa6",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5307bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbrucehu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f9655-316b-4506-b265-346270c1d046",
   "metadata": {},
   "source": [
    "API: 2999b8f99f0f62b4f64c48a1c8be9a16945183e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3beadc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def pipeline_audio(sess_id):\n",
    "    print(sess_id)\n",
    "    train_set, val_set, test_set = build_ds(sess_id)\n",
    "    \n",
    "    output_dir=os.path.join(\"/home/multi_modal_ser/finetune_encoder/check_pts\", \"HUBERT\", sess_id, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\"))\n",
    "\n",
    "    training_args = TrainingArguments(output_dir,report_to=\"wandb\")\n",
    "    training_args.remove_unused_columns=False\n",
    "    training_args.per_device_train_batch_size=40\n",
    "    training_args.per_device_eval_batch_size=20\n",
    "    training_args.logging_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "    training_args.eval_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "    training_args.evaluation_strategy=\"steps\" \n",
    "    training_args.logging_strategy=\"steps\"\n",
    "    training_args.load_best_model_at_end=True,\n",
    "    training_args.save_strategy = \"no\"\n",
    "    training_args.learning_rate=1e-3\n",
    "    training_args.num_train_epochs=1\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_set,\n",
    "        eval_dataset=val_set,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    trainer.evaluate()\n",
    "    test_result = trainer.predict(test_set)\n",
    "    \n",
    "    FREEZE_PROJ_PATH = \"/home/freeze/{}/projector\".format(sess_id)\n",
    "    FREEZE_CLAS_PATH = \"/home/freeze/{}/classifier\".format(sess_id)\n",
    "    os.makedirs(FREEZE_PROJ_PATH, exist_ok=True)\n",
    "    os.makedirs(FREEZE_CLAS_PATH, exist_ok=True)\n",
    "\n",
    "    FREEZE_PROJ = os.path.join(FREEZE_PROJ_PATH, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\")+\".pt\")\n",
    "    FREEZE_CLAS = os.path.join(FREEZE_CLAS_PATH, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\")+\".pt\")\n",
    "\n",
    "    torch.save(model.projector.state_dict(), FREEZE_PROJ)\n",
    "    torch.save(model.classifier.state_dict(), FREEZE_CLAS)\n",
    "\n",
    "    model.projector.load_state_dict(torch.load(FREEZE_PROJ))\n",
    "    model.classifier.load_state_dict(torch.load(FREEZE_CLAS))\n",
    "    \n",
    "    \n",
    "    json_object = json.dumps(test_result.metrics, indent=4)\n",
    "\n",
    "    # Writing to sample.json\n",
    "    with open(\"{}.json\".format(sess_id), \"w\") as outfile:\n",
    "        outfile.write(json_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sess_id in list(sess_dict.keys())[6:]:\n",
    "    pipeline_audio(sess_id)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
