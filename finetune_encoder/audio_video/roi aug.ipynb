{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d4075b",
   "metadata": {},
   "source": [
    "### Prepare Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041460cc-7376-4d29-b95d-156e4b21b530",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ChuakBlurk/vidaug\n",
      "  Cloning https://github.com/ChuakBlurk/vidaug to c:\\users\\legion\\appdata\\local\\temp\\pip-req-build-6rlr_m6k\n",
      "  Resolved https://github.com/ChuakBlurk/vidaug to commit f074c68d127cb6fadd2d7985e1bc3f633104d45d\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/ChuakBlurk/vidaug 'C:\\Users\\LEGION\\AppData\\Local\\Temp\\pip-req-build-6rlr_m6k'\n",
      "DEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting omegaconf==2.1.1\n",
      "  Using cached omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in d:\\anaconda\\lib\\site-packages (from omegaconf==2.1.1) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in d:\\anaconda\\lib\\site-packages (from omegaconf==2.1.1) (6.0)\n",
      "Installing collected packages: omegaconf\n",
      "  Attempting uninstall: omegaconf\n",
      "    Found existing installation: omegaconf 2.0.6\n",
      "    Uninstalling omegaconf-2.0.6:\n",
      "      Successfully uninstalled omegaconf-2.0.6\n",
      "Successfully installed omegaconf-2.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fairseq 1.0.0a0+afc77bd requires omegaconf<2.1, but you have omegaconf 2.1.1 which is incompatible.\n",
      "hydra-core 1.0.7 requires omegaconf<2.1,>=2.0.5, but you have omegaconf 2.1.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hydra-core==1.1.1\n",
      "  Using cached hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "Requirement already satisfied: omegaconf==2.1.* in d:\\anaconda\\lib\\site-packages (from hydra-core==1.1.1) (2.1.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in d:\\anaconda\\lib\\site-packages (from hydra-core==1.1.1) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in d:\\anaconda\\lib\\site-packages (from omegaconf==2.1.*->hydra-core==1.1.1) (6.0)\n",
      "Installing collected packages: hydra-core\n",
      "  Attempting uninstall: hydra-core\n",
      "    Found existing installation: hydra-core 1.0.7\n",
      "    Uninstalling hydra-core-1.0.7:\n",
      "      Successfully uninstalled hydra-core-1.0.7\n",
      "Successfully installed hydra-core-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fairseq 1.0.0a0+afc77bd requires hydra-core<1.1, but you have hydra-core 1.1.1 which is incompatible.\n",
      "fairseq 1.0.0a0+afc77bd requires omegaconf<2.1, but you have omegaconf 2.1.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23.5 in d:\\anaconda\\lib\\site-packages (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "'apt-get' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in d:\\anaconda\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.8 in d:\\anaconda\\lib\\site-packages (from scikit-image) (1.11.3)\n",
      "Requirement already satisfied: networkx>=2.8 in d:\\anaconda\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (10.0.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (2.31.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\anaconda\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from scikit-image) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\anaconda\\lib\\site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\anaconda\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in d:\\anaconda\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda\\lib\\site-packages (from datasets) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\anaconda\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in d:\\anaconda\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in d:\\anaconda\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in d:\\anaconda\\lib\\site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in d:\\anaconda\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in d:\\anaconda\\lib\\site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in d:\\anaconda\\lib\\site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in d:\\anaconda\\lib\\site-packages (from transformers[torch]) (0.24.1)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in d:\\anaconda\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in d:\\anaconda\\lib\\site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in d:\\anaconda\\lib\\site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.4.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from huggingface-hub->accelerate) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in d:\\anaconda\\lib\\site-packages (0.15.12)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in d:\\anaconda\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in d:\\anaconda\\lib\\site-packages (from wandb) (3.1.37)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from wandb) (2.29.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in d:\\anaconda\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in d:\\anaconda\\lib\\site-packages (from wandb) (1.32.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in d:\\anaconda\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in d:\\anaconda\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in d:\\anaconda\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in d:\\anaconda\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in d:\\anaconda\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in d:\\anaconda\\lib\\site-packages (from wandb) (4.24.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in d:\\anaconda\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\anaconda\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\anaconda\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ChuakBlurk/vidaug\n",
    "!pip install omegaconf==2.1.1\n",
    "!pip install hydra-core==1.1.1\n",
    "!pip install -U numpy==1.23.5\n",
    "!apt-get update && apt-get install -y python3-opencv\n",
    "!pip install opencv-python\n",
    "!pip install scikit-image \n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U\n",
    "!pip install wandb\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6c4388",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\university\\FYT\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'av_hubert'...\n",
      "Submodule 'fairseq' (https://github.com/pytorch/fairseq) registered for path 'fairseq'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule path 'fairseq': checked out 'afc77bdf4bb51453ce76f1572ef2ee6ddcda8eeb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'E:/university/FYT/repos/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in d:\\anaconda\\lib\\site-packages (from scipy) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in d:\\anaconda\\lib\\site-packages (0.1.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python_speech_features in d:\\anaconda\\lib\\site-packages (0.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-video in d:\\anaconda\\lib\\site-packages (1.1.11)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from scikit-video) (1.23.5)\n",
      "Requirement already satisfied: pillow in d:\\anaconda\\lib\\site-packages (from scikit-video) (10.0.1)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from scikit-video) (1.11.3)\n",
      "E:\\university\\FYT\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\\fairseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "DEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing e:\\university\\fyt\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\\fairseq\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: cffi in d:\\anaconda\\lib\\site-packages (from fairseq==1.0.0a0+afc77bd) (1.15.1)\n",
      "Requirement already satisfied: cython in d:\\anaconda\\lib\\site-packages (from fairseq==1.0.0a0+afc77bd) (3.0.0)\n",
      "Collecting hydra-core<1.1 (from fairseq==1.0.0a0+afc77bd)\n",
      "  Using cached hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "Collecting omegaconf<2.1 (from fairseq==1.0.0a0+afc77bd)\n",
      "  Using cached omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: regex in d:\\anaconda\\lib\\site-packages (from fairseq==1.0.0a0+afc77bd) (2023.10.3)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in d:\\anaconda\\lib\\site-packages (from fairseq==1.0.0a0+afc77bd) (2.3.1)\n",
      "Requirement already satisfied: torch in d:\\anaconda\\lib\\site-packages (from fairseq==1.0.0a0+afc77bd) (2.1.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from fairseq==1.0.0a0+afc77bd) (4.65.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from fairseq==1.0.0a0+afc77bd) (1.23.5)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in d:\\anaconda\\lib\\site-packages (from hydra-core<1.1->fairseq==1.0.0a0+afc77bd) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in d:\\anaconda\\lib\\site-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (6.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (4.7.1)\n",
      "Requirement already satisfied: portalocker in d:\\anaconda\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in d:\\anaconda\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.8.10)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.4.6)\n",
      "Requirement already satisfied: lxml in d:\\anaconda\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (4.9.3)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi->fairseq==1.0.0a0+afc77bd) (2.21)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.9.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch->fairseq==1.0.0a0+afc77bd) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch->fairseq==1.0.0a0+afc77bd) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch->fairseq==1.0.0a0+afc77bd) (2.1.1)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\anaconda\\lib\\site-packages (from portalocker->sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (305.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch->fairseq==1.0.0a0+afc77bd) (1.3.0)\n",
      "Building wheels for collected packages: fairseq\n",
      "  Building wheel for fairseq (pyproject.toml): started\n",
      "  Building wheel for fairseq (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fairseq: filename=fairseq-1.0.0a0+afc77bd-cp311-cp311-win_amd64.whl size=1540791 sha256=79f952d25f462ad31d5c0045cb81c5289786aa34ddb429a20271cb1acbeeda17\n",
      "  Stored in directory: C:\\Users\\LEGION\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-q394jijr\\wheels\\1c\\22\\a0\\6ca9529498e597bed970e1bf570719b98546e36080704a40a6\n",
      "Successfully built fairseq\n",
      "Installing collected packages: omegaconf, hydra-core, fairseq\n",
      "  Attempting uninstall: omegaconf\n",
      "    Found existing installation: omegaconf 2.1.1\n",
      "    Uninstalling omegaconf-2.1.1:\n",
      "      Successfully uninstalled omegaconf-2.1.1\n",
      "  Attempting uninstall: hydra-core\n",
      "    Found existing installation: hydra-core 1.1.1\n",
      "    Uninstalling hydra-core-1.1.1:\n",
      "      Successfully uninstalled hydra-core-1.1.1\n",
      "  Attempting uninstall: fairseq\n",
      "    Found existing installation: fairseq 1.0.0a0+afc77bd\n",
      "    Uninstalling fairseq-1.0.0a0+afc77bd:\n",
      "      Successfully uninstalled fairseq-1.0.0a0+afc77bd\n",
      "Successfully installed fairseq-1.0.0a0+afc77bd hydra-core-1.0.7 omegaconf-2.0.6\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ChuakBlurk/av_hubert.git\n",
    "\n",
    "%cd av_hubert\n",
    "!git submodule init\n",
    "!git submodule update\n",
    "!pip install scipy\n",
    "!pip install sentencepiece\n",
    "!pip install python_speech_features\n",
    "!pip install scikit-video\n",
    "\n",
    "%cd fairseq\n",
    "!pip install ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e231ede0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mutable default <class 'fairseq.dataclass.configs.CommonConfig'> for field common is not allowed: use default_factory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m checkpoint_utils, options, tasks, utils\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "File \u001b[1;32mE:\\university\\FYT\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\\fairseq\\fairseq\\__init__.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdb\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# backwards compatibility to support `from fairseq.X import Y`\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m distributed_utils\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m meters, metrics, progress_bar  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     23\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfairseq.distributed_utils\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m distributed_utils\n",
      "File \u001b[1;32mE:\\university\\FYT\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\\fairseq\\fairseq\\distributed\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed_timeout_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedTimeoutWrapper\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_sharded_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fsdp_enable_wrap, fsdp_wrap, FullyShardedDataParallel\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_distributed_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LegacyDistributedDataParallel\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_proxy_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleProxyWrapper\n",
      "File \u001b[1;32mE:\\university\\FYT\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\\fairseq\\fairseq\\distributed\\fully_sharded_data_parallel.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclass\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedTrainingConfig\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m dist_utils\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\university\\FYT\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\\fairseq\\fairseq\\dataclass\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FairseqDataclass\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChoiceEnum\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFairseqDataclass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChoiceEnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m ]\n",
      "File \u001b[1;32mE:\\university\\FYT\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\\fairseq\\fairseq\\dataclass\\configs.py:971\u001b[0m\n\u001b[0;32m    960\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m field(\n\u001b[0;32m    961\u001b[0m         default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    962\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread this many sentences into a buffer before processing them\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         },\n\u001b[0;32m    965\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m field(\n\u001b[0;32m    967\u001b[0m         default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile to read from; use - for stdin\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 971\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFairseqConfig\u001b[39;00m(FairseqDataclass):\n\u001b[0;32m    973\u001b[0m     common: CommonConfig \u001b[38;5;241m=\u001b[39m CommonConfig()\n\u001b[0;32m    974\u001b[0m     common_eval: CommonEvalConfig \u001b[38;5;241m=\u001b[39m CommonEvalConfig()\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\dataclasses.py:1230\u001b[0m, in \u001b[0;36mdataclass\u001b[1;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;66;03m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[1;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\dataclasses.py:1220\u001b[0m, in \u001b[0;36mdataclass.<locals>.wrap\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m-> 1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _process_class(\u001b[38;5;28mcls\u001b[39m, init, \u001b[38;5;28mrepr\u001b[39m, eq, order, unsafe_hash,\n\u001b[0;32m   1221\u001b[0m                           frozen, match_args, kw_only, slots,\n\u001b[0;32m   1222\u001b[0m                           weakref_slot)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\dataclasses.py:958\u001b[0m, in \u001b[0;36m_process_class\u001b[1;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[0;32m    955\u001b[0m         kw_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m         \u001b[38;5;66;03m# Otherwise it's a field of some type.\u001b[39;00m\n\u001b[1;32m--> 958\u001b[0m         cls_fields\u001b[38;5;241m.\u001b[39mappend(_get_field(\u001b[38;5;28mcls\u001b[39m, name, \u001b[38;5;28mtype\u001b[39m, kw_only))\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cls_fields:\n\u001b[0;32m    961\u001b[0m     fields[f\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m f\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\dataclasses.py:815\u001b[0m, in \u001b[0;36m_get_field\u001b[1;34m(cls, a_name, a_type, default_kw_only)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# For real fields, disallow mutable defaults.  Use unhashable as a proxy\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# indicator for mutability.  Read the __hash__ attribute from the class,\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;66;03m# not the instance.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_field_type \u001b[38;5;129;01mis\u001b[39;00m _FIELD \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdefault\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__hash__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutable default \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f\u001b[38;5;241m.\u001b[39mdefault)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for field \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    816\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed: use default_factory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[1;31mValueError\u001b[0m: mutable default <class 'fairseq.dataclass.configs.CommonConfig'> for field common is not allowed: use default_factory"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "import cv2\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import sys\n",
    "sys.path.append(\"/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\")\n",
    "%cd /home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/\n",
    "import utils as avhubert_utils\n",
    "from argparse import Namespace\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1442ff",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15addb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"E:/pretrained/check_pts/\")\n",
    "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/clean-pretrain/base_vox_iter4.pt -O E:/pretrained/check_pts/avhubert.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edf8e1",
   "metadata": {},
   "source": [
    "### Build Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7d434",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86df1ecf-343d-4464-824b-4adf070a8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e339c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_ds import AVHUBERTDataset\n",
    "mmser_ds = torch.load(\"/home/avhubert_ds2.pt\")\n",
    "mmser_ds.video_path = \"/home/roi/\"\n",
    "\n",
    "# outputs = model.extract_finetune(mmser_ds[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4043f023-01f6-4abc-aa9d-665b1ee7fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5531/5531 [03:11<00:00, 28.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# mmser_ds.cached = False\n",
    "# mmser_ds.__cache__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb06072",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da70288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_classifier import AVHUBERTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d940a",
   "metadata": {},
   "source": [
    "### Build Train Test DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c429bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_ = mmser_ds.df_\n",
    "mmser_ds.df_[\"bigsess\"] = mmser_ds.df_[\"session\"].apply(lambda x: x[:-1])\n",
    "sess_dict = mmser_ds.df_.groupby(\"bigsess\").groups\n",
    "all_indices = set(mmser_ds.df_.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a781f-52f2-4968-958b-f438c21c6216",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca1b078-b6fe-4432-9329-46bf5b25c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import vidaug.augmentors as va\n",
    "import random\n",
    "\n",
    "\n",
    "class VidaugDataset(Dataset):\n",
    "    \n",
    "    def collate(self, audio, video, max_size=500):\n",
    "        padded_audio = pad_sequence([torch.tensor(a.squeeze()) for a in audio]+[torch.empty(500, 104)], batch_first=True)[:-1]\n",
    "        padded_video = pad_sequence([v.squeeze().clone().detach() for v in video]+[torch.empty(500,88,88)], batch_first=True)[:-1, np.newaxis, : ,:,:]\n",
    "        mask = torch.zeros_like(padded_audio)\n",
    "        mask[padded_audio != 0] = 1\n",
    "        return padded_audio, padded_video, mask\n",
    "    \n",
    "    \n",
    "    def __init__(self, audio_feats_list, \n",
    "                 video_feats_list, \n",
    "                 text_list, \n",
    "                 labels_list, aug_prob=0.3):\n",
    "\n",
    "        self.label_smp_dict = {}\n",
    "        for idx, label in enumerate(labels_list):\n",
    "            if label not in self.label_smp_dict:\n",
    "                self.label_smp_dict[label] = []\n",
    "            self.label_smp_dict[label].append({\n",
    "                \"audio\": audio_feats_list[idx],\n",
    "                \"video\": video_feats_list[idx],\n",
    "                \"text\": text_list[idx],\n",
    "                \"label\": labels_list[idx],\n",
    "            })\n",
    "        self.aug = False\n",
    "        self.aug_len = 0\n",
    "        self.sometimes = lambda aug: va.Sometimes(aug_prob, aug) # Used to apply augmentor with 50% probability\n",
    "        \n",
    "        self.transform_list = [\n",
    "            self.sometimes(va.Salt()),\n",
    "            self.sometimes(va.Pepper()),\n",
    "            self.sometimes(va.RandomShear(0.2, 0.2)),\n",
    "            self.sometimes(va.HorizontalFlip()),\n",
    "            self.sometimes(va.VerticalFlip()),\n",
    "            self.sometimes(va.RandomRotate(30)),\n",
    "            self.sometimes(va.GaussianBlur(0.8)),\n",
    "            self.sometimes(va.ElasticTransformation(0.2,0.2)),\n",
    "            self.sometimes(va.PiecewiseAffineTransform(20,10,0.5)),\n",
    "        ]\n",
    "        \n",
    "\n",
    "    def __upsample__(self, origin_smp_list, smp_length, k=None):\n",
    "        smpled_list = origin_smp_list\n",
    "        for idx in tqdm(range(smp_length-len(origin_smp_list))):\n",
    "            seq = va.Sequential(random.choices(self.transform_list, k=k))\n",
    "            smp = random.choice(origin_smp_list)\n",
    "            vid = smp[\"video\"].squeeze()\n",
    "            vid = [cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB).astype(np.uint8) for frame in vid]\n",
    "            vid = np.stack(vid)\n",
    "            video_aug = seq(vid)\n",
    "            video_aug = [cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_RGB2GRAY).astype(np.uint8) for frame in video_aug]\n",
    "            video_aug = np.stack(video_aug)\n",
    "            video_aug = video_aug[np.newaxis, np.newaxis]\n",
    "            \n",
    "            smpled_list.append({\n",
    "                \"video\": video_aug,\n",
    "                \"audio\": smp['audio'],\n",
    "                \"text\": smp['text'],\n",
    "                \"label\": smp['label'],\n",
    "            })\n",
    "        return smpled_list\n",
    "            \n",
    "        \n",
    "    \n",
    "    def __aug__(self, niters=2, nchoice=2, isaug=True):\n",
    "        self.aug_label_smp_dict = {}\n",
    "        self.aug_smps = []\n",
    "        if isaug:\n",
    "            print([len(v) for k,v in self.label_smp_dict.items()])\n",
    "            smp_size = max([len(v) for k,v in self.label_smp_dict.items()])*(niters+1)\n",
    "            for k, v in self.label_smp_dict.items():\n",
    "                print(smp_size, len(v))\n",
    "                upsmped = self.__upsample__(v, smp_size, nchoice)\n",
    "                self.aug_label_smp_dict[k] = upsmped\n",
    "                self.aug_smps += upsmped\n",
    "                \n",
    "            self.aug = True\n",
    "            print([len(v) for k,v in self.aug_label_smp_dict.items()])\n",
    "        else:\n",
    "            print([len(v) for k,v in self.label_smp_dict.items()])\n",
    "            for k, v in self.label_smp_dict.items():\n",
    "                self.aug_label_smp_dict[k] = v\n",
    "                self.aug_smps += v\n",
    "            self.aug = True\n",
    "            print([len(v) for k,v in self.aug_label_smp_dict.items()])\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.aug_smps)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_feats = self.aug_smps[idx][\"audio\"]\n",
    "        video_feats = self.aug_smps[idx][\"video\"]/255\n",
    "        padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "        return {\n",
    "            \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "            \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "            \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "            \"text\": self.aug_smps[idx][\"text\"],\n",
    "            \"labels\": self.aug_smps[idx][\"label\"]\n",
    "        }\n",
    "\n",
    "# class VidaugDataset(Dataset):\n",
    "    \n",
    "#     def collate(self, audio, video, max_size=500):\n",
    "#         padded_audio = pad_sequence([torch.tensor(a.squeeze()) for a in audio]+[torch.empty(500, 104)], batch_first=True)[:-1]\n",
    "#         padded_video = pad_sequence([v.squeeze().clone().detach() for v in video]+[torch.empty(500,88,88)], batch_first=True)[:-1, np.newaxis, : ,:,:]\n",
    "#         mask = torch.zeros_like(padded_audio)\n",
    "#         mask[padded_audio != 0] = 1\n",
    "#         return padded_audio, padded_video, mask\n",
    "    \n",
    "    \n",
    "#     def __init__(self, audio_feats_list, \n",
    "#                  video_feats_list, \n",
    "#                  text_list, \n",
    "#                  labels_list):\n",
    "#         self.audio_feats_list = audio_feats_list\n",
    "#         self.video_feats_list = video_feats_list\n",
    "#         self.text_list = text_list\n",
    "#         self.labels_list = labels_list\n",
    "    \n",
    "#         print(len(self.audio_feats_list))\n",
    "#         print(len(self.video_feats_list))\n",
    "#         print(len(self.text_list))\n",
    "#         print(len(self.labels_list))\n",
    "        \n",
    "#         self.origin_len = len(self.labels_list)\n",
    "#         self.aug_len = 0\n",
    "\n",
    "    \n",
    "    \n",
    "#     def __aug__(self, niters=2, aug_prob=0.3, k=None):\n",
    "#         sometimes = lambda aug: va.Sometimes(aug_prob, aug) # Used to apply augmentor with 50% probability\n",
    "        \n",
    "#         transform_list = [\n",
    "#             # sometimes(va.InvertColor()),\n",
    "#             sometimes(va.Salt()),\n",
    "#             sometimes(va.Pepper()),\n",
    "#             sometimes(va.RandomShear(0.2, 0.2)),\n",
    "#             sometimes(va.HorizontalFlip()),\n",
    "#             sometimes(va.VerticalFlip()),\n",
    "#             sometimes(va.RandomRotate(30)),\n",
    "#             sometimes(va.GaussianBlur(0.8)),\n",
    "#             sometimes(va.ElasticTransformation(0.2,0.2)),\n",
    "#             sometimes(va.PiecewiseAffineTransform(20,10,0.5)),\n",
    "#         ]\n",
    "        \n",
    "        \n",
    "#         self.aug_audio_feats_list = []\n",
    "#         self.aug_video_feats_list = []\n",
    "#         self.aug_text_list = []\n",
    "#         self.aug_labels_list = []\n",
    "        \n",
    "#         for smp_id in tqdm(range(len(self.video_feats_list))):\n",
    "#             for i in range(niters):\n",
    "#                 if k is None:\n",
    "#                     seq = va.Sequential(random.choices(transform_list, \n",
    "#                                                    k=random.choice(range(len(transform_list)))))        \n",
    "#                 else:\n",
    "#                     seq = va.Sequential(random.choices(transform_list, \n",
    "#                                                    k=k))\n",
    "#                 vid = self.video_feats_list[smp_id].squeeze()\n",
    "#                 # change to color \n",
    "#                 vid = [cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB).astype(np.uint8) for frame in vid]\n",
    "#                 vid = np.stack(vid)\n",
    "#                 video_aug = seq(vid)\n",
    "#                 # print(video_aug[0].shape)\n",
    "#                 video_aug = [cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_RGB2GRAY).astype(np.uint8) for frame in video_aug]\n",
    "#                 video_aug = np.stack(video_aug)\n",
    "                \n",
    "#                 # transform = avhubert_utils.Compose([\n",
    "#                 #   avhubert_utils.Normalize(0.0, 255.0),\n",
    "#                 #   avhubert_utils.CenterCrop((88, 88)),\n",
    "#                 #   avhubert_utils.Normalize(0.421, 0.165)])\n",
    "#                 # video_aug = transform(video_aug)[np.newaxis, np.newaxis]\n",
    "\n",
    "#                 video_aug = (video_aug/255)[np.newaxis, np.newaxis]\n",
    "\n",
    "                \n",
    "#                 video_aug = torch.tensor(video_aug)\n",
    "#                 self.aug_audio_feats_list.append(self.audio_feats_list[smp_id])\n",
    "#                 self.aug_video_feats_list.append(video_aug)\n",
    "#                 self.aug_text_list.append(self.text_list[smp_id])\n",
    "#                 self.aug_labels_list.append(self.labels_list[smp_id])\n",
    "                \n",
    "#         self.aug_len = len(self.aug_labels_list)\n",
    "                \n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.origin_len + self.aug_len\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         if idx < self.origin_len:\n",
    "#             audio_feats = self.audio_feats_list[idx]\n",
    "#             video_feats = self.video_feats_list[idx]\n",
    "#             padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "#             return {\n",
    "#                 \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "#                 \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "#                 \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "#                 \"text\": self.text_list[idx],\n",
    "#                 \"labels\": self.labels_list[idx]\n",
    "#             }\n",
    "#         else:\n",
    "#             idx = idx - self.origin_len\n",
    "#             audio_feats = self.aug_audio_feats_list[idx]\n",
    "#             video_feats = self.aug_video_feats_list[idx]\n",
    "#             padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "#             return {\n",
    "#                 \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "#                 \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "#                 \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "#                 \"text\": self.aug_text_list[idx],\n",
    "#                 \"labels\": self.aug_labels_list[idx]\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f90f1e8f-2234-4722-a4d0-535048f8077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feats_list = mmser_ds.audio_feats_list\n",
    "video_feats_list = mmser_ds.video_feats_list\n",
    "text_list = list(meta_df_[\"transcript\"])\n",
    "labels_list = list(meta_df_[\"emotion_id\"])\n",
    "\n",
    "del mmser_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fed7638-bfe1-4fe9-b11a-ef464dcfc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = sess_dict['Ses03']\n",
    "test_indices = sess_dict['Ses04']\n",
    "train_indices = list(all_indices-set(val_indices)-set(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "543c179e-1903-4419-a2fd-c33e9e9c0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in train_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in train_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in train_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in train_indices]\n",
    ")\n",
    "\n",
    "val_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in val_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in val_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in val_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in val_indices]\n",
    ")\n",
    "\n",
    "test_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in test_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in test_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in test_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in test_indices]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1c1dc6d-8d9e-4015-9fa4-0b9893a25c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0, 3.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de096d1d-6742-4cb2-aff1-015943b0b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1130, 536, 636, 1047]\n",
      "3390 1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [01:07<00:00, 33.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2854/2854 [01:43<00:00, 27.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2754/2754 [01:58<00:00, 23.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2343/2343 [01:20<00:00, 29.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3390, 3390, 3390, 3390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds.__aug__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "012878dd-d857-4742-9436-f714036d0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320, 286, 305, 240]\n",
      "[320, 286, 305, 240]\n",
      "[327, 143, 303, 258]\n",
      "[327, 143, 303, 258]\n"
     ]
    }
   ],
   "source": [
    "val_ds.__aug__(isaug=False)\n",
    "test_ds.__aug__(isaug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69a7c46a-08eb-45dc-8b11-f0bbbdb6d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13560\n",
      "1151\n",
      "1031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500, 88, 88])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(val_ds))\n",
    "print(len(test_ds))\n",
    "train_ds[0][\"video\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573929b",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be847c2-4282-4906-8add-40136adb8012",
   "metadata": {},
   "source": [
    "API: 2999b8f99f0f62b4f64c48a1c8be9a16945183e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2329893c-3888-4ff6-b37e-b1b538afb36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: pre-trained w/o fine-tuning\n"
     ]
    }
   ],
   "source": [
    "user_dir = \"/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"/home/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdb496-80eb-43b3-afaf-5bdc2f9cac3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecfde834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmser\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/wandb/run-20231126_113751-q9brhlr9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mmser/av_hubert/runs/q9brhlr9' target=\"_blank\">leafy-water-31</a></strong> to <a href='https://wandb.ai/mmser/av_hubert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mmser/av_hubert' target=\"_blank\">https://wandb.ai/mmser/av_hubert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mmser/av_hubert/runs/q9brhlr9' target=\"_blank\">https://wandb.ai/mmser/av_hubert/runs/q9brhlr9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 256)\n",
    "for param in avhubert_classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "wandb.init()\n",
    "train_set = train_ds\n",
    "val_set = val_ds\n",
    "test_set = test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be934063-6dd4-4911-af28-d52cd19a3cb2",
   "metadata": {},
   "source": [
    "### Change resnet weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdbe8200-c1a1-4f0c-8486-d61f38fbd52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in /opt/conda/lib/python3.10/site-packages (2.5.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (1.23.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (2.31.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (0.16.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (10.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (2023.7.22)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision->facenet-pytorch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision->facenet-pytorch) (1.3.0)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb6c8673-22c3-49ff-b504-ad5e3fce69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "# avhubert_classifier.encoder.feature_extractor_video.resnet = InceptionResnetV1(pretrained='vggface2')\n",
    "avhubert_classifier = avhubert_classifier.to(device)\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "341a9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=os.path.join(\"check_pts\", \"AVHUBERT\", datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\"))\n",
    "\n",
    "training_args = TrainingArguments(output_dir,report_to=\"wandb\")\n",
    "training_args.remove_unused_columns=False\n",
    "training_args.per_device_train_batch_size=6\n",
    "training_args.per_device_eval_batch_size=6\n",
    "training_args.logging_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "training_args.eval_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "training_args.evaluation_strategy=\"steps\" \n",
    "training_args.logging_strategy=\"steps\"\n",
    "training_args.load_best_model_at_end=True,\n",
    "training_args.save_strategy = \"no\"\n",
    "training_args.learning_rate=5e-4\n",
    "training_args.num_train_epochs=7\n",
    "training_args.metric_for_best_model = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27ade4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from avhubert_trainer import CustomTrainer , compute_metrics\n",
    "from transformers import EarlyStoppingCallback, TrainerCallback, TrainerState\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=avhubert_classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6778b05-02f5-4598-86ed-2a69d88a1323",
   "metadata": {},
   "source": [
    "##### Gradual Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7a1b316-8b55-4e88-bbf0-32e4d8e271dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreezingCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, freeze_encoder_epochs: int):\n",
    "        self.freeze_encoder_epochs = freeze_encoder_epochs\n",
    "\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        print(state.epoch, self.freeze_encoder_epochs)\n",
    "        model = kwargs[\"model\"]\n",
    "        if state.epoch >= self.freeze_encoder_epochs:\n",
    "            print(\"=\"*10, \"Freezing\", \"=\"*10)\n",
    "            for param in model.encoder.feature_extractor_video.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90bf04a5-0861-4dba-917b-3a23fdfff97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing_callback = FreezingCallback(3)\n",
    "# trainer.add_callback(freezing_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5f342fd-5ad9-47c6-9858-1b6b721a1f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3955' max='3955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3955/3955 58:10, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wa</th>\n",
       "      <th>Ua</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.355800</td>\n",
       "      <td>1.358300</td>\n",
       "      <td>0.339705</td>\n",
       "      <td>0.317154</td>\n",
       "      <td>0.259902</td>\n",
       "      <td>0.339705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>1.165100</td>\n",
       "      <td>1.532366</td>\n",
       "      <td>0.286707</td>\n",
       "      <td>0.284726</td>\n",
       "      <td>0.233411</td>\n",
       "      <td>0.286707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>1.064800</td>\n",
       "      <td>1.378476</td>\n",
       "      <td>0.405734</td>\n",
       "      <td>0.422984</td>\n",
       "      <td>0.388735</td>\n",
       "      <td>0.405734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>0.962300</td>\n",
       "      <td>1.163713</td>\n",
       "      <td>0.460469</td>\n",
       "      <td>0.462050</td>\n",
       "      <td>0.449978</td>\n",
       "      <td>0.460469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.899600</td>\n",
       "      <td>1.186505</td>\n",
       "      <td>0.489140</td>\n",
       "      <td>0.482242</td>\n",
       "      <td>0.480727</td>\n",
       "      <td>0.489140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0.819600</td>\n",
       "      <td>1.252298</td>\n",
       "      <td>0.465682</td>\n",
       "      <td>0.470297</td>\n",
       "      <td>0.467991</td>\n",
       "      <td>0.465682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1162</td>\n",
       "      <td>0.737700</td>\n",
       "      <td>1.499683</td>\n",
       "      <td>0.448306</td>\n",
       "      <td>0.460640</td>\n",
       "      <td>0.433103</td>\n",
       "      <td>0.448306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1328</td>\n",
       "      <td>0.670900</td>\n",
       "      <td>1.336341</td>\n",
       "      <td>0.448306</td>\n",
       "      <td>0.461748</td>\n",
       "      <td>0.437618</td>\n",
       "      <td>0.448306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1494</td>\n",
       "      <td>0.630600</td>\n",
       "      <td>1.524807</td>\n",
       "      <td>0.479583</td>\n",
       "      <td>0.485950</td>\n",
       "      <td>0.463860</td>\n",
       "      <td>0.479583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>1.508802</td>\n",
       "      <td>0.471764</td>\n",
       "      <td>0.482031</td>\n",
       "      <td>0.463269</td>\n",
       "      <td>0.471764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1826</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>1.573647</td>\n",
       "      <td>0.486533</td>\n",
       "      <td>0.484876</td>\n",
       "      <td>0.479737</td>\n",
       "      <td>0.486533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>1.591361</td>\n",
       "      <td>0.485665</td>\n",
       "      <td>0.489298</td>\n",
       "      <td>0.489824</td>\n",
       "      <td>0.485665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2158</td>\n",
       "      <td>0.420700</td>\n",
       "      <td>1.533822</td>\n",
       "      <td>0.482189</td>\n",
       "      <td>0.485916</td>\n",
       "      <td>0.484613</td>\n",
       "      <td>0.482189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2324</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>1.566857</td>\n",
       "      <td>0.500434</td>\n",
       "      <td>0.501234</td>\n",
       "      <td>0.488173</td>\n",
       "      <td>0.500434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>0.338400</td>\n",
       "      <td>1.522591</td>\n",
       "      <td>0.490877</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.495398</td>\n",
       "      <td>0.490877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2656</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>1.511691</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.497660</td>\n",
       "      <td>0.496477</td>\n",
       "      <td>0.496090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2822</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>1.625139</td>\n",
       "      <td>0.470895</td>\n",
       "      <td>0.480806</td>\n",
       "      <td>0.460871</td>\n",
       "      <td>0.470895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2988</td>\n",
       "      <td>0.274500</td>\n",
       "      <td>1.768984</td>\n",
       "      <td>0.500434</td>\n",
       "      <td>0.504936</td>\n",
       "      <td>0.490588</td>\n",
       "      <td>0.500434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3154</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>1.650185</td>\n",
       "      <td>0.504778</td>\n",
       "      <td>0.509184</td>\n",
       "      <td>0.497859</td>\n",
       "      <td>0.504778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>1.658888</td>\n",
       "      <td>0.507385</td>\n",
       "      <td>0.509182</td>\n",
       "      <td>0.502150</td>\n",
       "      <td>0.507385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3486</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>1.810356</td>\n",
       "      <td>0.495222</td>\n",
       "      <td>0.496903</td>\n",
       "      <td>0.499909</td>\n",
       "      <td>0.495222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3652</td>\n",
       "      <td>0.203500</td>\n",
       "      <td>1.696134</td>\n",
       "      <td>0.498697</td>\n",
       "      <td>0.498269</td>\n",
       "      <td>0.498005</td>\n",
       "      <td>0.498697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3818</td>\n",
       "      <td>0.194300</td>\n",
       "      <td>1.720964</td>\n",
       "      <td>0.504778</td>\n",
       "      <td>0.506340</td>\n",
       "      <td>0.504409</td>\n",
       "      <td>0.504778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/multi_modal_ser/finetune_encoder/audio_video/avhubert_trainer.py:34: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3955, training_loss=0.5553600398086567, metrics={'train_runtime': 3494.4136, 'train_samples_per_second': 27.163, 'train_steps_per_second': 1.132, 'total_flos': 0.0, 'train_loss': 0.5553600398086567, 'epoch': 7.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73117560-10f3-484d-813e-af68d15761cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53544a-76b0-4ab5-b22b-f4979adfa195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0829d84-db7b-46f5-9363-8cf7e5d57cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f2bba2c6-d14c-47b4-a81b-c4c56d3ef80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86cada-d000-4da5-bff4-09d1a5254029",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = trainer.predict(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f14d3-0bbc-4719-9d33-51ac39db7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c74dd-72b3-46d4-8e41-94309b0d2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_labels = val_preds.predictions.argmax(axis=1)\n",
    "true_labels = val_preds.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b34e23-f64d-41ff-83ba-c1117cdea3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_labels[10:15])\n",
    "print(true_labels[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e003f-bf5b-4342-a795-794a7fa0cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33504e25-c1e4-4a04-b6b6-888cd94d7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(true_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea3c3b-cc75-47a4-b06d-3f90bd720484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1832c-d791-4271-8f75-b9370915e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d2156-d8b1-4b4e-821e-24a4e8df145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(true_labels, pred_labels, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0c521-e2a9-4b2f-8e27-b7e0563ace08",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "output = loss(torch.tensor(val_preds.predictions), torch.tensor(true_labels).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52c24b-edbf-4784-8e69-eb26c806a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef31267",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "test_result = trainer.predict(test_set).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40875ee9-9164-4545-b53f-dc2a9e210777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83889a1d-fb15-4e01-9690-307e0650526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da509cb2-d2af-4235-b631-337cb7964263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163a9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00358b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967ebfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
