{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d4075b",
   "metadata": {},
   "source": [
    "### Prepare Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a67b949-fd3b-4316-bef9-0f3146caf870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_HOME\"]=\"/data/chuak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "041460cc-7376-4d29-b95d-156e4b21b530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ChuakBlurk/vidaug\n",
      "  Cloning https://github.com/ChuakBlurk/vidaug to /tmp/pip-req-build-0zx6qul2\n",
      "  Running command git clone -q https://github.com/ChuakBlurk/vidaug /tmp/pip-req-build-0zx6qul2\n",
      "  Resolved https://github.com/ChuakBlurk/vidaug to commit f074c68d127cb6fadd2d7985e1bc3f633104d45d\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: omegaconf==2.1.1 in /data/chuak/mmser/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf==2.1.1) (6.0.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf==2.1.1) (4.8)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: hydra-core==1.1.1 in /data/chuak/mmser/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /data/chuak/mmser/lib/python3.10/site-packages (from hydra-core==1.1.1) (4.8)\n",
      "Requirement already satisfied: omegaconf==2.1.* in /data/chuak/mmser/lib/python3.10/site-packages (from hydra-core==1.1.1) (2.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf==2.1.*->hydra-core==1.1.1) (6.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy==1.23.5 in /data/chuak/mmser/lib/python3.10/site-packages (1.23.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "apt-get: Command not found.\n",
      "Requirement already satisfied: opencv-python in /data/chuak/mmser/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /data/chuak/mmser/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-image in /data/chuak/mmser/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (10.1.0)\n",
      "Requirement already satisfied: numpy>=1.22 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (1.23.5)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (2023.12.9)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (0.3)\n",
      "Requirement already satisfied: scipy>=1.8 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (1.11.4)\n",
      "Requirement already satisfied: networkx>=2.8 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: imageio>=2.27 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: packaging>=21 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (23.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: transformers in /data/chuak/mmser/lib/python3.10/site-packages (4.36.1)\n",
      "Requirement already satisfied: requests in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: datasets in /data/chuak/mmser/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: aiohttp in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: multiprocess in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: pyarrow-hotfix in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pandas in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: xxhash in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: packaging in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /data/chuak/mmser/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /data/chuak/mmser/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /data/chuak/mmser/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /data/chuak/mmser/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /data/chuak/mmser/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /data/chuak/mmser/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data/chuak/mmser/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /data/chuak/mmser/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /data/chuak/mmser/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "pip: No match.\n",
      "Requirement already satisfied: accelerate in /data/chuak/mmser/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: pyyaml in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: triton==2.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: sympy in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: typing-extensions in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: jinja2 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: networkx in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /data/chuak/mmser/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: requests in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/chuak/mmser/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/chuak/mmser/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: wandb in /data/chuak/mmser/lib/python3.10/site-packages (0.16.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (1.39.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: PyYAML in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (4.25.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (5.9.6)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: setuptools in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (57.4.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /data/chuak/mmser/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /data/chuak/mmser/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /data/chuak/mmser/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /data/chuak/mmser/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: facenet-pytorch in /data/chuak/mmser/lib/python3.10/site-packages (2.5.3)\n",
      "Requirement already satisfied: torchvision in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (0.16.2)\n",
      "Requirement already satisfied: requests in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (2.31.0)\n",
      "Requirement already satisfied: pillow in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (10.1.0)\n",
      "Requirement already satisfied: numpy in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (1.23.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: torch==2.1.2 in /data/chuak/mmser/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.1.2)\n",
      "Requirement already satisfied: sympy in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (1.12)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: networkx in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: jinja2 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: fsspec in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /data/chuak/mmser/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchvision->facenet-pytorch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/chuak/mmser/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchvision->facenet-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/chuak/mmser/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchvision->facenet-pytorch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ChuakBlurk/vidaug\n",
    "!pip install omegaconf==2.1.1\n",
    "!pip install hydra-core==1.1.1\n",
    "!pip install -U numpy==1.23.5\n",
    "!apt-get update && apt-get install -y python3-opencv\n",
    "!pip install opencv-python\n",
    "!pip install scikit-image \n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U\n",
    "!pip install wandb\n",
    "!pip install scikit-learn\n",
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6c4388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'av_hubert' already exists and is not an empty directory.\n",
      "Requirement already satisfied: facenet-pytorch in /data/chuak/mmser/lib/python3.10/site-packages (2.5.3)\n",
      "Requirement already satisfied: pillow in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (10.1.0)\n",
      "Requirement already satisfied: numpy in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (1.23.5)\n",
      "Requirement already satisfied: torchvision in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (0.16.2)\n",
      "Requirement already satisfied: requests in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.6)\n",
      "Requirement already satisfied: torch==2.1.2 in /data/chuak/mmser/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.1.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: sympy in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (4.9.0)\n",
      "Requirement already satisfied: fsspec in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2023.10.0)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2.18.1)\n",
      "Requirement already satisfied: jinja2 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /data/chuak/mmser/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchvision->facenet-pytorch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/chuak/mmser/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchvision->facenet-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/chuak/mmser/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchvision->facenet-pytorch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /data/chuak/mmser/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /data/chuak/mmser/lib/python3.10/site-packages (from scipy) (1.23.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /data/chuak/mmser/lib/python3.10/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: python_speech_features in /data/chuak/mmser/lib/python3.10/site-packages (0.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-video in /data/chuak/mmser/lib/python3.10/site-packages (1.1.11)\n",
      "Requirement already satisfied: pillow in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-video) (10.1.0)\n",
      "Requirement already satisfied: numpy in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-video) (1.23.5)\n",
      "Requirement already satisfied: scipy in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-video) (1.11.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq\n",
      "Processing /data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting omegaconf<2.1\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (2.4.0)\n",
      "Requirement already satisfied: cffi in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (1.16.0)\n",
      "Requirement already satisfied: torch in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (2.1.2)\n",
      "Requirement already satisfied: cython in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (3.0.6)\n",
      "Requirement already satisfied: regex in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (2023.10.3)\n",
      "Requirement already satisfied: numpy in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (1.23.5)\n",
      "Requirement already satisfied: tqdm in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (4.66.1)\n",
      "Collecting hydra-core<1.1\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 12.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.8 in /data/chuak/mmser/lib/python3.10/site-packages (from hydra-core<1.1->fairseq==1.0.0a0) (4.8)\n",
      "Requirement already satisfied: typing-extensions in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0) (6.0.1)\n",
      "Requirement already satisfied: colorama in /data/chuak/mmser/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0) (0.4.6)\n",
      "Requirement already satisfied: portalocker in /data/chuak/mmser/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0) (2.8.2)\n",
      "Requirement already satisfied: lxml in /data/chuak/mmser/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0) (4.9.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /data/chuak/mmser/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0) (0.9.0)\n",
      "Requirement already satisfied: pycparser in /data/chuak/mmser/lib/python3.10/site-packages (from cffi->fairseq==1.0.0a0) (2.21)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (11.4.5.107)\n",
      "Requirement already satisfied: sympy in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (1.12)\n",
      "Requirement already satisfied: jinja2 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.105)\n",
      "Requirement already satisfied: networkx in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /data/chuak/mmser/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq==1.0.0a0) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/chuak/mmser/lib/python3.10/site-packages (from jinja2->torch->fairseq==1.0.0a0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/chuak/mmser/lib/python3.10/site-packages (from sympy->torch->fairseq==1.0.0a0) (1.3.0)\n",
      "Building wheels for collected packages: fairseq\n",
      "  Building wheel for fairseq (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-1.0.0a0-cp310-cp310-linux_x86_64.whl size=1574555 sha256=fed11b441e0cff10e3154161fd9f0e820d946564db259f6f17ff0f8abdc6bfb1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8tya65dr/wheels/d4/32/4e/6609ee8c1e034611dc5697daff9f1dcd6ae7ab29e84d729a11\n",
      "Successfully built fairseq\n",
      "Installing collected packages: omegaconf, hydra-core, fairseq\n",
      "  Attempting uninstall: omegaconf\n",
      "    Found existing installation: omegaconf 2.1.1\n",
      "    Uninstalling omegaconf-2.1.1:\n",
      "      Successfully uninstalled omegaconf-2.1.1\n",
      "  Attempting uninstall: hydra-core\n",
      "    Found existing installation: hydra-core 1.1.1\n",
      "    Uninstalling hydra-core-1.1.1:\n",
      "      Successfully uninstalled hydra-core-1.1.1\n",
      "  Attempting uninstall: fairseq\n",
      "    Found existing installation: fairseq 1.0.0a0\n",
      "    Uninstalling fairseq-1.0.0a0:\n",
      "      Successfully uninstalled fairseq-1.0.0a0\n",
      "Successfully installed fairseq-1.0.0a0 hydra-core-1.0.7 omegaconf-2.0.6\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ChuakBlurk/av_hubert.git\n",
    "!pip install facenet-pytorch\n",
    "%cd av_hubert\n",
    "!git submodule init\n",
    "!git submodule update\n",
    "!pip install scipy\n",
    "!pip install sentencepiece\n",
    "!pip install python_speech_features\n",
    "!pip install scikit-video\n",
    "\n",
    "%cd fairseq\n",
    "!pip install ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e231ede0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/'\n",
      "/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video\n",
      "3.10.0 (default, Oct  6 2021, 10:19:31) [GCC 8.3.1 20190311 (Red Hat 8.3.1-3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "import cv2\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import sys\n",
    "sys.path.append(\"/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\")\n",
    "%cd /home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/\n",
    "import utils as avhubert_utils\n",
    "from argparse import Namespace\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482e14c8-1996-4515-bc23-e7b3ca5e07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmser\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/wandb/run-20231219_211809-o8ci9717</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/o8ci9717' target=\"_blank\">genial-terrain-5</a></strong> to <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video' target=\"_blank\">https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/o8ci9717' target=\"_blank\">https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/o8ci9717</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/o8ci9717?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fce13c25b10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1442ff",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15addb93",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/data/chuak/mmser/check_pts/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data/chuak/mmser/check_pts/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/clean-pretrain/base_vox_iter4.pt -O /data/chuak/mmser/check_pts/avhubert.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/bin/../packages/python/python-3.10/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/data/chuak/mmser/check_pts/'"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"/data/chuak/mmser/check_pts/\")\n",
    "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/clean-pretrain/base_vox_iter4.pt -O /data/chuak/mmser/check_pts/avhubert.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edf8e1",
   "metadata": {},
   "source": [
    "### Build Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7d434",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e339c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_ds import AVHUBERTDataset\n",
    "mmser_ds = torch.load(\"/data/chuak/mmser/data/avhubert_ds2.pt\")\n",
    "mmser_ds.video_path = \"/data/chuak/mmser/data/roi/\"\n",
    "mmser_ds.cached = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4043f023-01f6-4abc-aa9d-665b1ee7fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████▊                              | 2492/5531 [03:01<03:41, 13.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mmser_ds\u001b[38;5;241m.\u001b[39mcached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmmser_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__cache__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/avhubert_ds.py:140\u001b[0m, in \u001b[0;36mAVHUBERTDataset.__cache__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmp_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn_list))):\n\u001b[0;32m--> 140\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getsingle__\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m     \n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_feats_list\u001b[38;5;241m.\u001b[39mappend(res[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_feats_list\u001b[38;5;241m.\u001b[39mappend(res[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/avhubert_ds.py:104\u001b[0m, in \u001b[0;36mAVHUBERTDataset.__getsingle__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    102\u001b[0m raw_audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_list[idx]\n\u001b[1;32m    103\u001b[0m now \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 104\u001b[0m video_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load_video__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m audio_feats \u001b[38;5;241m=\u001b[39m logfbank(raw_audio, samplerate\u001b[38;5;241m=\u001b[39mAUDIORATE)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;66;03m# [T, F]\u001b[39;00m\n\u001b[1;32m    107\u001b[0m audio_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacker(audio_feats, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_in_features\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m26\u001b[39m) \u001b[38;5;66;03m# [T/stack_order_audio, F*stack_order_audio]\u001b[39;00m\n",
      "File \u001b[0;32m/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/avhubert_ds.py:72\u001b[0m, in \u001b[0;36mAVHUBERTDataset.__load_video__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__load_video__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 72\u001b[0m     frames \u001b[38;5;241m=\u001b[39m \u001b[43mavhubert_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     transform \u001b[38;5;241m=\u001b[39m avhubert_utils\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     74\u001b[0m       avhubert_utils\u001b[38;5;241m.\u001b[39mNormalize(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m255.0\u001b[39m),\n\u001b[1;32m     75\u001b[0m       avhubert_utils\u001b[38;5;241m.\u001b[39mCenterCrop((\u001b[38;5;241m88\u001b[39m, \u001b[38;5;241m88\u001b[39m)),\n\u001b[1;32m     76\u001b[0m       avhubert_utils\u001b[38;5;241m.\u001b[39mNormalize(\u001b[38;5;241m0.421\u001b[39m, \u001b[38;5;241m0.165\u001b[39m)])\n\u001b[1;32m     77\u001b[0m     frames \u001b[38;5;241m=\u001b[39m transform(frames)\n",
      "File \u001b[0;32m/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert/utils.py:19\u001b[0m, in \u001b[0;36mload_video\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m     21\u001b[0m         frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mmser_ds.cached = False\n",
    "mmser_ds.__cache__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb06072",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da70288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_classifier import AVHUBERTClassifier\n",
    "user_dir = \"/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"/data/chuak/mmser/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39fdee-d129-4d3c-a33e-9080f1c52a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba04b0-5935-42b7-b1eb-4280068d6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avhubert_classifier(**mmser_ds[:3])\n",
    "avhubert_res = avhubert_classifier.encoder.feature_extractor_video.resnet\n",
    "video_input = mmser_ds[:3][\"video\"]\n",
    "avhubert_res_output = avhubert_res(video_input)\n",
    "print(video_input.shape)\n",
    "print(avhubert_res_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd0a81-4f10-4a21-af57-0cc845b7ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class FaceNetBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, facenet):\n",
    "        super(FaceNetBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 3\n",
    "        self.facenet = facenet\n",
    "    def forward(self, x):\n",
    "        x = self.facenet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb381d5-42e7-48a4-bcc4-30d21adb00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "facenet_res = InceptionResnetV1(pretrained='vggface2')\n",
    "faceNetBlock = FaceNetBlock(64, facenet_res)\n",
    "avhubert_classifier.encoder.feature_extractor_video.resnet.trunk = faceNetBlock\n",
    "avhubert_classifier.encoder.feature_extractor_video.resnet.frontend3D =nn.Conv3d(1, 3, \n",
    "                                      kernel_size=(5, 7, 7), \n",
    "                                      stride=(1, 1, 1), \n",
    "                                      padding=(2, 3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b33d2-ae42-4533-9e09-b5fd7304c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avhubert_classifier(**mmser_ds[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d940a",
   "metadata": {},
   "source": [
    "### Build Train Test DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c429bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_ = mmser_ds.df_\n",
    "mmser_ds.df_[\"bigsess\"] = mmser_ds.df_[\"session\"].apply(lambda x: x[:-1])\n",
    "sess_dict = mmser_ds.df_.groupby(\"bigsess\").groups\n",
    "all_indices = set(mmser_ds.df_.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a781f-52f2-4968-958b-f438c21c6216",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca1b078-b6fe-4432-9329-46bf5b25c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import vidaug.augmentors as va\n",
    "import random\n",
    "\n",
    "\n",
    "class VidaugDataset(Dataset):\n",
    "    \n",
    "    def collate(self, audio, video, max_size=500):\n",
    "        padded_audio = pad_sequence([torch.tensor(a.squeeze()) for a in audio]+[torch.empty(500, 104)], batch_first=True)[:-1]\n",
    "        padded_video = pad_sequence([v.squeeze().clone().detach() for v in video]+[torch.empty(500,88,88)], batch_first=True)[:-1, np.newaxis, : ,:,:]\n",
    "        mask = torch.zeros_like(padded_audio)\n",
    "        mask[padded_audio != 0] = 1\n",
    "        return padded_audio, padded_video, mask\n",
    "    \n",
    "    \n",
    "    def __init__(self, audio_feats_list, \n",
    "                 video_feats_list, \n",
    "                 text_list, \n",
    "                 labels_list, aug_prob=0.3):\n",
    "\n",
    "        self.label_smp_dict = {}\n",
    "        for idx, label in enumerate(labels_list):\n",
    "            if label not in self.label_smp_dict:\n",
    "                self.label_smp_dict[label] = []\n",
    "            self.label_smp_dict[label].append({\n",
    "                \"audio\": audio_feats_list[idx],\n",
    "                \"video\": video_feats_list[idx],\n",
    "                \"text\": text_list[idx],\n",
    "                \"label\": labels_list[idx],\n",
    "            })\n",
    "        self.aug = False\n",
    "        self.aug_len = 0\n",
    "        self.sometimes = lambda aug: va.Sometimes(aug_prob, aug) # Used to apply augmentor with 50% probability\n",
    "        \n",
    "        self.transform_list = [\n",
    "            self.sometimes(va.Salt()),\n",
    "            self.sometimes(va.Pepper()),\n",
    "            self.sometimes(va.RandomShear(0.2, 0.2)),\n",
    "            self.sometimes(va.HorizontalFlip()),\n",
    "            self.sometimes(va.VerticalFlip()),\n",
    "            self.sometimes(va.RandomRotate(30)),\n",
    "            self.sometimes(va.GaussianBlur(0.8)),\n",
    "            self.sometimes(va.ElasticTransformation(0.2,0.2)),\n",
    "            self.sometimes(va.PiecewiseAffineTransform(20,10,0.5)),\n",
    "        ]\n",
    "        \n",
    "\n",
    "    def __upsample__(self, origin_smp_list, smp_length, k=None):\n",
    "        smpled_list = origin_smp_list\n",
    "        for idx in tqdm(range(smp_length-len(origin_smp_list))):\n",
    "            seq = va.Sequential(random.choices(self.transform_list, k=k))\n",
    "            smp = random.choice(origin_smp_list)\n",
    "            vid = smp[\"video\"].squeeze()\n",
    "            vid = [cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB).astype(np.uint8) for frame in vid]\n",
    "            vid = np.stack(vid)\n",
    "            video_aug = seq(vid)\n",
    "            video_aug = [cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_RGB2GRAY).astype(np.uint8) for frame in video_aug]\n",
    "            video_aug = np.stack(video_aug)\n",
    "            video_aug = video_aug[np.newaxis, np.newaxis]\n",
    "            \n",
    "            smpled_list.append({\n",
    "                \"video\": video_aug,\n",
    "                \"audio\": smp['audio'],\n",
    "                \"text\": smp['text'],\n",
    "                \"label\": smp['label'],\n",
    "            })\n",
    "        return smpled_list\n",
    "            \n",
    "        \n",
    "    \n",
    "    def __aug__(self, niters=2, nchoice=2, isaug=True):\n",
    "        self.aug_label_smp_dict = {}\n",
    "        self.aug_smps = []\n",
    "        if isaug:\n",
    "            print([len(v) for k,v in self.label_smp_dict.items()])\n",
    "            smp_size = max([len(v) for k,v in self.label_smp_dict.items()])*(niters+1)\n",
    "            for k, v in self.label_smp_dict.items():\n",
    "                print(smp_size, len(v))\n",
    "                upsmped = self.__upsample__(v, smp_size, nchoice)\n",
    "                self.aug_label_smp_dict[k] = upsmped\n",
    "                self.aug_smps += upsmped\n",
    "                \n",
    "            self.aug = True\n",
    "            print([len(v) for k,v in self.aug_label_smp_dict.items()])\n",
    "        else:\n",
    "            print([len(v) for k,v in self.label_smp_dict.items()])\n",
    "            for k, v in self.label_smp_dict.items():\n",
    "                self.aug_label_smp_dict[k] = v\n",
    "                self.aug_smps += v\n",
    "            self.aug = True\n",
    "            print([len(v) for k,v in self.aug_label_smp_dict.items()])\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.aug_smps)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_feats = self.aug_smps[idx][\"audio\"]\n",
    "        video_feats = self.aug_smps[idx][\"video\"]/255\n",
    "        padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "        return {\n",
    "            \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "            \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "            \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "            \"text\": self.aug_smps[idx][\"text\"],\n",
    "            \"labels\": self.aug_smps[idx][\"label\"]\n",
    "        }\n",
    "\n",
    "# class VidaugDataset(Dataset):\n",
    "    \n",
    "#     def collate(self, audio, video, max_size=500):\n",
    "#         padded_audio = pad_sequence([torch.tensor(a.squeeze()) for a in audio]+[torch.empty(500, 104)], batch_first=True)[:-1]\n",
    "#         padded_video = pad_sequence([v.squeeze().clone().detach() for v in video]+[torch.empty(500,88,88)], batch_first=True)[:-1, np.newaxis, : ,:,:]\n",
    "#         mask = torch.zeros_like(padded_audio)\n",
    "#         mask[padded_audio != 0] = 1\n",
    "#         return padded_audio, padded_video, mask\n",
    "    \n",
    "    \n",
    "#     def __init__(self, audio_feats_list, \n",
    "#                  video_feats_list, \n",
    "#                  text_list, \n",
    "#                  labels_list):\n",
    "#         self.audio_feats_list = audio_feats_list\n",
    "#         self.video_feats_list = video_feats_list\n",
    "#         self.text_list = text_list\n",
    "#         self.labels_list = labels_list\n",
    "    \n",
    "#         print(len(self.audio_feats_list))\n",
    "#         print(len(self.video_feats_list))\n",
    "#         print(len(self.text_list))\n",
    "#         print(len(self.labels_list))\n",
    "        \n",
    "#         self.origin_len = len(self.labels_list)\n",
    "#         self.aug_len = 0\n",
    "\n",
    "    \n",
    "    \n",
    "#     def __aug__(self, niters=2, aug_prob=0.3, k=None):\n",
    "#         sometimes = lambda aug: va.Sometimes(aug_prob, aug) # Used to apply augmentor with 50% probability\n",
    "        \n",
    "#         transform_list = [\n",
    "#             # sometimes(va.InvertColor()),\n",
    "#             sometimes(va.Salt()),\n",
    "#             sometimes(va.Pepper()),\n",
    "#             sometimes(va.RandomShear(0.2, 0.2)),\n",
    "#             sometimes(va.HorizontalFlip()),\n",
    "#             sometimes(va.VerticalFlip()),\n",
    "#             sometimes(va.RandomRotate(30)),\n",
    "#             sometimes(va.GaussianBlur(0.8)),\n",
    "#             sometimes(va.ElasticTransformation(0.2,0.2)),\n",
    "#             sometimes(va.PiecewiseAffineTransform(20,10,0.5)),\n",
    "#         ]\n",
    "        \n",
    "        \n",
    "#         self.aug_audio_feats_list = []\n",
    "#         self.aug_video_feats_list = []\n",
    "#         self.aug_text_list = []\n",
    "#         self.aug_labels_list = []\n",
    "        \n",
    "#         for smp_id in tqdm(range(len(self.video_feats_list))):\n",
    "#             for i in range(niters):\n",
    "#                 if k is None:\n",
    "#                     seq = va.Sequential(random.choices(transform_list, \n",
    "#                                                    k=random.choice(range(len(transform_list)))))        \n",
    "#                 else:\n",
    "#                     seq = va.Sequential(random.choices(transform_list, \n",
    "#                                                    k=k))\n",
    "#                 vid = self.video_feats_list[smp_id].squeeze()\n",
    "#                 # change to color \n",
    "#                 vid = [cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB).astype(np.uint8) for frame in vid]\n",
    "#                 vid = np.stack(vid)\n",
    "#                 video_aug = seq(vid)\n",
    "#                 # print(video_aug[0].shape)\n",
    "#                 video_aug = [cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_RGB2GRAY).astype(np.uint8) for frame in video_aug]\n",
    "#                 video_aug = np.stack(video_aug)\n",
    "                \n",
    "#                 # transform = avhubert_utils.Compose([\n",
    "#                 #   avhubert_utils.Normalize(0.0, 255.0),\n",
    "#                 #   avhubert_utils.CenterCrop((88, 88)),\n",
    "#                 #   avhubert_utils.Normalize(0.421, 0.165)])\n",
    "#                 # video_aug = transform(video_aug)[np.newaxis, np.newaxis]\n",
    "\n",
    "#                 video_aug = (video_aug/255)[np.newaxis, np.newaxis]\n",
    "\n",
    "                \n",
    "#                 video_aug = torch.tensor(video_aug)\n",
    "#                 self.aug_audio_feats_list.append(self.audio_feats_list[smp_id])\n",
    "#                 self.aug_video_feats_list.append(video_aug)\n",
    "#                 self.aug_text_list.append(self.text_list[smp_id])\n",
    "#                 self.aug_labels_list.append(self.labels_list[smp_id])\n",
    "                \n",
    "#         self.aug_len = len(self.aug_labels_list)\n",
    "                \n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.origin_len + self.aug_len\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         if idx < self.origin_len:\n",
    "#             audio_feats = self.audio_feats_list[idx]\n",
    "#             video_feats = self.video_feats_list[idx]\n",
    "#             padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "#             return {\n",
    "#                 \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "#                 \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "#                 \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "#                 \"text\": self.text_list[idx],\n",
    "#                 \"labels\": self.labels_list[idx]\n",
    "#             }\n",
    "#         else:\n",
    "#             idx = idx - self.origin_len\n",
    "#             audio_feats = self.aug_audio_feats_list[idx]\n",
    "#             video_feats = self.aug_video_feats_list[idx]\n",
    "#             padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "#             return {\n",
    "#                 \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "#                 \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "#                 \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "#                 \"text\": self.aug_text_list[idx],\n",
    "#                 \"labels\": self.aug_labels_list[idx]\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f90f1e8f-2234-4722-a4d0-535048f8077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feats_list = mmser_ds.audio_feats_list\n",
    "video_feats_list = mmser_ds.video_feats_list\n",
    "text_list = list(meta_df_[\"transcript\"])\n",
    "labels_list = list(meta_df_[\"emotion_id\"])\n",
    "\n",
    "del mmser_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fed7638-bfe1-4fe9-b11a-ef464dcfc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = sess_dict['Ses03']\n",
    "test_indices = sess_dict['Ses04']\n",
    "train_indices = list(all_indices-set(val_indices)-set(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543c179e-1903-4419-a2fd-c33e9e9c0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in train_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in train_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in train_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in train_indices]\n",
    ")\n",
    "\n",
    "val_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in val_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in val_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in val_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in val_indices]\n",
    ")\n",
    "\n",
    "test_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in test_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in test_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in test_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in test_indices]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c1dc6d-8d9e-4015-9fa4-0b9893a25c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0, 3.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de096d1d-6742-4cb2-aff1-015943b0b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1130, 536, 636, 1047]\n",
      "3390 1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2260/2260 [01:35<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2854/2854 [02:26<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2754/2754 [02:53<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2343/2343 [01:46<00:00, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3390, 3390, 3390, 3390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds.__aug__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "012878dd-d857-4742-9436-f714036d0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320, 286, 305, 240]\n",
      "[320, 286, 305, 240]\n",
      "[327, 143, 303, 258]\n",
      "[327, 143, 303, 258]\n"
     ]
    }
   ],
   "source": [
    "val_ds.__aug__(isaug=False)\n",
    "test_ds.__aug__(isaug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a7c46a-08eb-45dc-8b11-f0bbbdb6d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13560\n",
      "1151\n",
      "1031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500, 88, 88])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(val_ds))\n",
    "print(len(test_ds))\n",
    "train_ds[0][\"video\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573929b",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be847c2-4282-4906-8add-40136adb8012",
   "metadata": {},
   "source": [
    "API: 2999b8f99f0f62b4f64c48a1c8be9a16945183e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2329893c-3888-4ff6-b37e-b1b538afb36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: pre-trained w/o fine-tuning\n"
     ]
    }
   ],
   "source": [
    "from avhubert_classifier import AVHUBERTClassifier\n",
    "user_dir = \"/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"/data/chuak/mmser/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdb496-80eb-43b3-afaf-5bdc2f9cac3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfde834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmser\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/wandb/run-20231217_165201-gamfee8b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/gamfee8b' target=\"_blank\">silvery-snowball-3</a></strong> to <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video' target=\"_blank\">https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/gamfee8b' target=\"_blank\">https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/gamfee8b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "# avhubert_classifier = AVHUBERTClassifier(model, 768, 256)\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 64)\n",
    "for param in avhubert_classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "wandb.init()\n",
    "train_set = train_ds\n",
    "val_set = val_ds\n",
    "test_set = test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be934063-6dd4-4911-af28-d52cd19a3cb2",
   "metadata": {},
   "source": [
    "### Change resnet weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb6c8673-22c3-49ff-b504-ad5e3fce69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "# avhubert_classifier.encoder.feature_extractor_video.resnet = InceptionResnetV1(pretrained='vggface2')\n",
    "avhubert_classifier = avhubert_classifier.to(device)\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 32)\n",
    "\n",
    "facenet_res = InceptionResnetV1(pretrained='vggface2')\n",
    "faceNetBlock = facenet_res\n",
    "avhubert_classifier.encoder.feature_extractor_video.resnet.trunk = faceNetBlock\n",
    "avhubert_classifier.encoder.feature_extractor_video.resnet.frontend3D =nn.Conv3d(1, 3, \n",
    "                                      kernel_size=(5, 7, 7), \n",
    "                                      stride=(1, 1, 1), \n",
    "                                      padding=(2, 3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "341a9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=os.path.join(\"check_pts\", \"AVHUBERT\", datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\"))\n",
    "\n",
    "training_args = TrainingArguments(output_dir,report_to=\"wandb\")\n",
    "training_args.remove_unused_columns=False\n",
    "training_args.per_device_train_batch_size=2\n",
    "training_args.per_device_eval_batch_size=2\n",
    "training_args.logging_steps = int(1000/training_args.per_device_train_batch_size/8)\n",
    "training_args.eval_steps = int(1000/training_args.per_device_train_batch_size/8)\n",
    "training_args.evaluation_strategy=\"steps\" \n",
    "training_args.logging_strategy=\"steps\"\n",
    "training_args.load_best_model_at_end=True,\n",
    "training_args.save_strategy = \"no\"\n",
    "training_args.learning_rate=5e-4\n",
    "training_args.num_train_epochs=7\n",
    "training_args.metric_for_best_model = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27ade4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from avhubert_trainer import CustomTrainer , compute_metrics\n",
    "from transformers import EarlyStoppingCallback, TrainerCallback, TrainerState\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=avhubert_classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6778b05-02f5-4598-86ed-2a69d88a1323",
   "metadata": {},
   "source": [
    "##### Gradual Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7a1b316-8b55-4e88-bbf0-32e4d8e271dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreezingCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, freeze_encoder_epochs: int):\n",
    "        self.freeze_encoder_epochs = freeze_encoder_epochs\n",
    "\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        print(state.epoch, self.freeze_encoder_epochs)\n",
    "        model = kwargs[\"model\"]\n",
    "        if state.epoch >= self.freeze_encoder_epochs:\n",
    "            print(\"=\"*10, \"Freezing\", \"=\"*10)\n",
    "            for param in model.encoder.feature_extractor_video.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13dec778-5859-43c9-bc0c-90dcd24bac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90bf04a5-0861-4dba-917b-3a23fdfff97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing_callback = FreezingCallback(3)\n",
    "# trainer.add_callback(freezing_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f342fd-5ad9-47c6-9858-1b6b721a1f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='5936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 129/5936 59:54 < 45:38:54, 0.04 it/s, Epoch 0.15/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wa</th>\n",
       "      <th>Ua</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.399800</td>\n",
       "      <td>1.430543</td>\n",
       "      <td>0.248480</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.098908</td>\n",
       "      <td>0.248480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.398200</td>\n",
       "      <td>1.413233</td>\n",
       "      <td>0.248480</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.098908</td>\n",
       "      <td>0.248480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/avhubert_trainer.py:34: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\")\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73117560-10f3-484d-813e-af68d15761cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53544a-76b0-4ab5-b22b-f4979adfa195",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(faceNetBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0829d84-db7b-46f5-9363-8cf7e5d57cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11186688"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(avhubert_classifier.encoder.feature_extractor_video.resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2bba2c6-d14c-47b4-a81b-c4c56d3ef80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86cada-d000-4da5-bff4-09d1a5254029",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = trainer.predict(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f14d3-0bbc-4719-9d33-51ac39db7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c74dd-72b3-46d4-8e41-94309b0d2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_labels = val_preds.predictions.argmax(axis=1)\n",
    "true_labels = val_preds.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b34e23-f64d-41ff-83ba-c1117cdea3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_labels[10:15])\n",
    "print(true_labels[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e003f-bf5b-4342-a795-794a7fa0cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33504e25-c1e4-4a04-b6b6-888cd94d7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(true_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea3c3b-cc75-47a4-b06d-3f90bd720484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1832c-d791-4271-8f75-b9370915e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d2156-d8b1-4b4e-821e-24a4e8df145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(true_labels, pred_labels, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0c521-e2a9-4b2f-8e27-b7e0563ace08",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "output = loss(torch.tensor(val_preds.predictions), torch.tensor(true_labels).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52c24b-edbf-4784-8e69-eb26c806a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef31267",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "test_result = trainer.predict(test_set).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40875ee9-9164-4545-b53f-dc2a9e210777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83889a1d-fb15-4e01-9690-307e0650526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da509cb2-d2af-4235-b631-337cb7964263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163a9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00358b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967ebfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
