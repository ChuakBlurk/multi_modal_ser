{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d4075b",
   "metadata": {},
   "source": [
    "### Prepare Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a67b949-fd3b-4316-bef9-0f3146caf870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_HOME\"]=\"/data/chuak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041460cc-7376-4d29-b95d-156e4b21b530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ChuakBlurk/vidaug\n",
      "  Cloning https://github.com/ChuakBlurk/vidaug to /tmp/pip-req-build-ne15wtzk\n",
      "  Running command git clone -q https://github.com/ChuakBlurk/vidaug /tmp/pip-req-build-ne15wtzk\n",
      "  Resolved https://github.com/ChuakBlurk/vidaug to commit f074c68d127cb6fadd2d7985e1bc3f633104d45d\n",
      "Using legacy 'setup.py install' for vidaug, since package 'wheel' is not installed.\n",
      "Installing collected packages: vidaug\n",
      "    Running setup.py install for vidaug ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed vidaug-0.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting omegaconf==2.1.1\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 744 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 20.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf==2.1.1) (6.0.1)\n",
      "Using legacy 'setup.py install' for antlr4-python3-runtime, since package 'wheel' is not installed.\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
      "    Running setup.py install for antlr4-python3-runtime ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed antlr4-python3-runtime-4.8 omegaconf-2.1.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting hydra-core==1.1.1\n",
      "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: omegaconf==2.1.* in /data/chuak/mmser/lib/python3.10/site-packages (from hydra-core==1.1.1) (2.1.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /data/chuak/mmser/lib/python3.10/site-packages (from hydra-core==1.1.1) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf==2.1.*->hydra-core==1.1.1) (6.0.1)\n",
      "Installing collected packages: hydra-core\n",
      "Successfully installed hydra-core-1.1.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numpy==1.23.5\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.1 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.23.5\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "apt-get: Command not found.\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 61.7 MB 56 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /data/chuak/mmser/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.1.78\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.7 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (23.2)\n",
      "Collecting imageio>=2.27\n",
      "  Downloading imageio-2.33.1-py3-none-any.whl (313 kB)\n",
      "\u001b[K     |████████████████████████████████| 313 kB 69.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-image) (1.23.5)\n",
      "Collecting networkx>=2.8\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 77.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=9.0.1\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 57.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lazy_loader>=0.3\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Collecting scipy>=1.8\n",
      "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 36.4 MB 125 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2023.12.9-py3-none-any.whl (223 kB)\n",
      "\u001b[K     |████████████████████████████████| 223 kB 72.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pillow, tifffile, scipy, networkx, lazy-loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.33.1 lazy-loader-0.3 networkx-3.2.1 pillow-10.1.0 scikit-image-0.22.0 scipy-1.11.4 tifffile-2023.12.9\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.3 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 73.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[K     |████████████████████████████████| 773 kB 75.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 77.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /data/chuak/mmser/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 2.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[K     |████████████████████████████████| 311 kB 83.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[K     |████████████████████████████████| 168 kB 76.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Installing collected packages: tqdm, fsspec, filelock, huggingface-hub, tokenizers, safetensors, regex, transformers\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.12.2 huggingface-hub-0.19.4 regex-2023.10.3 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.36.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "\u001b[K     |████████████████████████████████| 521 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 31.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 74.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3 MB 24.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-14.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 38.1 MB 219 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: packaging in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 71.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.18.0 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (0.19.4)\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 76.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/chuak/mmser/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 67.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 72.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 73.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /data/chuak/mmser/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 37.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[K     |████████████████████████████████| 502 kB 69.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /data/chuak/mmser/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[K     |████████████████████████████████| 341 kB 75.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /data/chuak/mmser/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, tzdata, pytz, fsspec, dill, aiohttp, xxhash, pyarrow-hotfix, pyarrow, pandas, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.12.2\n",
      "    Uninstalling fsspec-2023.12.2:\n",
      "      Successfully uninstalled fsspec-2023.12.2\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.15.0 dill-0.3.7 frozenlist-1.4.1 fsspec-2023.10.0 multidict-6.0.4 multiprocess-0.70.15 pandas-2.1.4 pyarrow-14.0.1 pyarrow-hotfix-0.6 pytz-2023.3.post1 tzdata-2023.3 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "pip: No match.\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "\u001b[K     |████████████████████████████████| 265 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: pyyaml in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Collecting torch>=1.10.0\n",
      "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 670.2 MB 1.3 kB/s  eta 0:00:01    |███▍                            | 70.0 MB 47.2 MB/s eta 0:00:13     |████████████▊                   | 266.6 MB 48.5 MB/s eta 0:00:09     |██████████████▌                 | 304.3 MB 48.5 MB/s eta 0:00:08     |████████████████████            | 417.1 MB 43.1 MB/s eta 0:00:06     |████████████████████████▋       | 515.5 MB 816 kB/s eta 0:03:10\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/chuak/mmser/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Collecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 209.8 MB 16 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 72.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 45.9 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 23.0 MB/s eta 0:00:01    |███████████████████████         | 87.3 MB 49.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 80.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: networkx in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 83.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 97.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 46.5 MB/s eta 0:00:01     |██████████████████              | 109.7 MB 43.2 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 41.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 113.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /data/chuak/mmser/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Collecting triton==2.1.0\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 89.2 MB 41.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 731.7 MB 72 kB/s s eta 0:00:015   |█▍                              | 33.0 MB 99.6 MB/s eta 0:00:08     |█████████▏                      | 209.2 MB 101.3 MB/s eta 0:00:06     |███████████████████▊            | 450.7 MB 37.5 MB/s eta 0:00:08     |████████████████████            | 459.6 MB 37.5 MB/s eta 0:00:08\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.5 MB 77.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /data/chuak/mmser/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/chuak/mmser/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 84.3 MB/s eta 0:00:01█████                  | 235 kB 84.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cublas-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, torch, accelerate\n",
      "Successfully installed accelerate-0.25.0 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.1.2 triton-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (57.4.0)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n",
      "\u001b[K     |████████████████████████████████| 254 kB 41.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[K     |████████████████████████████████| 190 kB 33.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,<5,>=3.19.0\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (5.9.6)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: PyYAML in /data/chuak/mmser/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Collecting Click!=8.0.0,>=7.1\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 18.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /data/chuak/mmser/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 5.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Installing collected packages: smmap, gitdb, setproctitle, sentry-sdk, protobuf, GitPython, docker-pycreds, Click, appdirs, wandb\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.40 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 protobuf-4.25.1 sentry-sdk-1.39.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.8 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[K     |████████████████████████████████| 302 kB 63.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 threadpoolctl-3.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting facenet-pytorch\n",
      "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (2.31.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 60.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (10.1.0)\n",
      "Requirement already satisfied: numpy in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (1.23.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: torch==2.1.2 in /data/chuak/mmser/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: fsspec in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2.18.1)\n",
      "Requirement already satisfied: sympy in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (1.12)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: networkx in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /data/chuak/mmser/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchvision->facenet-pytorch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/chuak/mmser/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchvision->facenet-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/chuak/mmser/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchvision->facenet-pytorch) (1.3.0)\n",
      "Installing collected packages: torchvision, facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.3 torchvision-0.16.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ChuakBlurk/vidaug\n",
    "!pip install omegaconf==2.1.1\n",
    "!pip install hydra-core==1.1.1\n",
    "!pip install -U numpy==1.23.5\n",
    "!apt-get update && apt-get install -y python3-opencv\n",
    "!pip install opencv-python\n",
    "!pip install scikit-image \n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U\n",
    "!pip install wandb\n",
    "!pip install scikit-learn\n",
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6c4388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n",
      "Cloning into 'av_hubert'...\n",
      "remote: Enumerating objects: 115, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 115 (delta 1), reused 4 (delta 0), pack-reused 108\u001b[K\n",
      "\u001b[KReceiving objects: 100% (115/115), 4.61 MiB | 3.39 MiB/s, done.\n",
      "\u001b[KResolving deltas: 100% (47/47), done.\n",
      "Requirement already satisfied: facenet-pytorch in /data/chuak/mmser/lib/python3.10/site-packages (2.5.3)\n",
      "Requirement already satisfied: torchvision in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (0.16.2)\n",
      "Requirement already satisfied: pillow in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (10.1.0)\n",
      "Requirement already satisfied: requests in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (2.31.0)\n",
      "Requirement already satisfied: numpy in /data/chuak/mmser/lib/python3.10/site-packages (from facenet-pytorch) (1.23.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/chuak/mmser/lib/python3.10/site-packages (from requests->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: torch==2.1.2 in /data/chuak/mmser/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.1.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: sympy in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (1.12)\n",
      "Requirement already satisfied: triton==2.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: fsspec in /data/chuak/mmser/lib/python3.10/site-packages (from torch==2.1.2->torchvision->facenet-pytorch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /data/chuak/mmser/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchvision->facenet-pytorch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/chuak/mmser/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchvision->facenet-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/chuak/mmser/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchvision->facenet-pytorch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule 'fairseq' (https://github.com/pytorch/fairseq) registered for path 'fairseq'\n",
      "Cloning into '/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq'...\n",
      "Submodule path 'fairseq': checked out 'afc77bdf4bb51453ce76f1572ef2ee6ddcda8eeb'\n",
      "Requirement already satisfied: scipy in /data/chuak/mmser/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /data/chuak/mmser/lib/python3.10/site-packages (from scipy) (1.23.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting python_speech_features\n",
      "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
      "Using legacy 'setup.py install' for python-speech-features, since package 'wheel' is not installed.\n",
      "Installing collected packages: python-speech-features\n",
      "    Running setup.py install for python-speech-features ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed python-speech-features-0.6\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scikit-video\n",
      "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-video) (1.11.4)\n",
      "Requirement already satisfied: numpy in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-video) (1.23.5)\n",
      "Requirement already satisfied: pillow in /data/chuak/mmser/lib/python3.10/site-packages (from scikit-video) (10.1.0)\n",
      "Installing collected packages: scikit-video\n",
      "Successfully installed scikit-video-1.1.11\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n",
      "/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq\n",
      "Processing /data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: regex in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (2023.10.3)\n",
      "Requirement already satisfied: numpy in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (1.23.5)\n",
      "Requirement already satisfied: torch in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (2.1.2)\n",
      "Collecting sacrebleu>=1.4.12\n",
      "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hydra-core<1.1\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 20.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cython\n",
      "  Downloading Cython-3.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 25.4 MB/s eta 0:00:01     |████▉                           | 542 kB 25.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting omegaconf<2.1\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: cffi in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /data/chuak/mmser/lib/python3.10/site-packages (from fairseq==1.0.0a0) (4.66.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /data/chuak/mmser/lib/python3.10/site-packages (from hydra-core<1.1->fairseq==1.0.0a0) (4.8)\n",
      "Requirement already satisfied: typing-extensions in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /data/chuak/mmser/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0) (6.0.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 31.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pycparser in /data/chuak/mmser/lib/python3.10/site-packages (from cffi->fairseq==1.0.0a0) (2.21)\n",
      "Requirement already satisfied: fsspec in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.3.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (10.3.2.106)\n",
      "Requirement already satisfied: networkx in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (3.2.1)\n",
      "Requirement already satisfied: filelock in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (3.13.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (8.9.2.26)\n",
      "Requirement already satisfied: jinja2 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.105)\n",
      "Requirement already satisfied: sympy in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /data/chuak/mmser/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /data/chuak/mmser/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->fairseq==1.0.0a0) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/chuak/mmser/lib/python3.10/site-packages (from jinja2->torch->fairseq==1.0.0a0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /data/chuak/mmser/lib/python3.10/site-packages (from sympy->torch->fairseq==1.0.0a0) (1.3.0)\n",
      "Building wheels for collected packages: fairseq\n",
      "  Building wheel for fairseq (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-1.0.0a0-cp310-cp310-linux_x86_64.whl size=1574555 sha256=16b2ab5c9b2a06543049a995e95e67e6d1b6701c2cd3c46be468351505c77aa4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4fx19t22/wheels/d4/32/4e/6609ee8c1e034611dc5697daff9f1dcd6ae7ab29e84d729a11\n",
      "Successfully built fairseq\n",
      "Installing collected packages: tabulate, portalocker, omegaconf, lxml, colorama, sacrebleu, hydra-core, cython, fairseq\n",
      "  Attempting uninstall: omegaconf\n",
      "    Found existing installation: omegaconf 2.1.1\n",
      "    Uninstalling omegaconf-2.1.1:\n",
      "      Successfully uninstalled omegaconf-2.1.1\n",
      "  Attempting uninstall: hydra-core\n",
      "    Found existing installation: hydra-core 1.1.1\n",
      "    Uninstalling hydra-core-1.1.1:\n",
      "      Successfully uninstalled hydra-core-1.1.1\n",
      "Successfully installed colorama-0.4.6 cython-3.0.6 fairseq-1.0.0a0 hydra-core-1.0.7 lxml-4.9.3 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.0 tabulate-0.9.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/data/chuak/mmser/bin/python-csd-3.10 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ChuakBlurk/av_hubert.git\n",
    "!pip install facenet-pytorch\n",
    "%cd av_hubert\n",
    "!git submodule init\n",
    "!git submodule update\n",
    "!pip install scipy\n",
    "!pip install sentencepiece\n",
    "!pip install python_speech_features\n",
    "!pip install scikit-video\n",
    "\n",
    "%cd fairseq\n",
    "!pip install ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e231ede0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/'\n",
      "/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video\n",
      "3.10.0 (default, Oct  6 2021, 10:19:31) [GCC 8.3.1 20190311 (Red Hat 8.3.1-3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "import cv2\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import sys\n",
    "sys.path.append(\"/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\")\n",
    "%cd /home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/\n",
    "import utils as avhubert_utils\n",
    "from argparse import Namespace\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482e14c8-1996-4515-bc23-e7b3ca5e07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmser\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/wandb/run-20231217_220911-xk2rpxzg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/xk2rpxzg' target=\"_blank\">jolly-fire-4</a></strong> to <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video' target=\"_blank\">https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/xk2rpxzg' target=\"_blank\">https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/xk2rpxzg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/xk2rpxzg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc76dc3dff0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1442ff",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15addb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-17 14:43:47--  https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/clean-pretrain/base_vox_iter4.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 54.192.18.81, 54.192.18.51, 54.192.18.50, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|54.192.18.81|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1237096561 (1.2G) [binary/octet-stream]\n",
      "Saving to: ‘/data/chuak/mmser/check_pts/avhubert.pt’\n",
      "\n",
      "100%[====================================>] 1,237,096,561 29.6MB/s   in 20s    \n",
      "\n",
      "2023-12-17 14:44:07 (60.1 MB/s) - ‘/data/chuak/mmser/check_pts/avhubert.pt’ saved [1237096561/1237096561]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"/data/chuak/mmser/check_pts/\")\n",
    "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/clean-pretrain/base_vox_iter4.pt -O /data/chuak/mmser/check_pts/avhubert.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edf8e1",
   "metadata": {},
   "source": [
    "### Build Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7d434",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e339c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_ds import AVHUBERTDataset\n",
    "mmser_ds = torch.load(\"/data/chuak/mmser/data/avhubert_ds2.pt\")\n",
    "mmser_ds.video_path = \"/data/chuak/mmser/data/roi/\"\n",
    "mmser_ds.cached = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4043f023-01f6-4abc-aa9d-665b1ee7fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 5531/5531 [06:12<00:00, 14.85it/s]\n"
     ]
    }
   ],
   "source": [
    "mmser_ds.cached = False\n",
    "mmser_ds.__cache__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb06072",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9da70288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: pre-trained w/o fine-tuning\n"
     ]
    }
   ],
   "source": [
    "from avhubert_classifier import AVHUBERTClassifier\n",
    "user_dir = \"/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"/data/chuak/mmser/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39fdee-d129-4d3c-a33e-9080f1c52a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbba04b0-5935-42b7-b1eb-4280068d6eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 500, 88, 88])\n",
      "torch.Size([3, 512, 500])\n"
     ]
    }
   ],
   "source": [
    "avhubert_classifier(**mmser_ds[:3])\n",
    "avhubert_res = avhubert_classifier.encoder.feature_extractor_video.resnet\n",
    "video_input = mmser_ds[:3][\"video\"]\n",
    "avhubert_res_output = avhubert_res(video_input)\n",
    "print(video_input.shape)\n",
    "print(avhubert_res_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1cd0a81-4f10-4a21-af57-0cc845b7ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class FaceNetBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, facenet):\n",
    "        super(FaceNetBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = 3\n",
    "        self.facenet = facenet\n",
    "    def forward(self, x):\n",
    "        x = self.facenet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbb381d5-42e7-48a4-bcc4-30d21adb00e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1532daec34b246c39cd24bd650eb307c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/107M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "facenet_res = InceptionResnetV1(pretrained='vggface2')\n",
    "faceNetBlock = FaceNetBlock(64, facenet_res)\n",
    "avhubert_classifier.encoder.feature_extractor_video.resnet.trunk = faceNetBlock\n",
    "avhubert_classifier.encoder.feature_extractor_video.resnet.frontend3D =nn.Conv3d(1, 3, \n",
    "                                      kernel_size=(5, 7, 7), \n",
    "                                      stride=(1, 1, 1), \n",
    "                                      padding=(2, 3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae0b33d2-ae42-4533-9e09-b5fd7304c3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[ 0.0430,  0.0747,  0.0209, -0.1072],\n",
       "         [ 0.0325,  0.0462, -0.0331, -0.1135],\n",
       "         [ 0.0051,  0.0418,  0.0020, -0.1445]], grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avhubert_classifier(**mmser_ds[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d940a",
   "metadata": {},
   "source": [
    "### Build Train Test DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c429bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_ = mmser_ds.df_\n",
    "mmser_ds.df_[\"bigsess\"] = mmser_ds.df_[\"session\"].apply(lambda x: x[:-1])\n",
    "sess_dict = mmser_ds.df_.groupby(\"bigsess\").groups\n",
    "all_indices = set(mmser_ds.df_.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a781f-52f2-4968-958b-f438c21c6216",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca1b078-b6fe-4432-9329-46bf5b25c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import vidaug.augmentors as va\n",
    "import random\n",
    "\n",
    "\n",
    "class VidaugDataset(Dataset):\n",
    "    \n",
    "    def collate(self, audio, video, max_size=500):\n",
    "        padded_audio = pad_sequence([torch.tensor(a.squeeze()) for a in audio]+[torch.empty(500, 104)], batch_first=True)[:-1]\n",
    "        padded_video = pad_sequence([v.squeeze().clone().detach() for v in video]+[torch.empty(500,88,88)], batch_first=True)[:-1, np.newaxis, : ,:,:]\n",
    "        mask = torch.zeros_like(padded_audio)\n",
    "        mask[padded_audio != 0] = 1\n",
    "        return padded_audio, padded_video, mask\n",
    "    \n",
    "    \n",
    "    def __init__(self, audio_feats_list, \n",
    "                 video_feats_list, \n",
    "                 text_list, \n",
    "                 labels_list, aug_prob=0.3):\n",
    "\n",
    "        self.label_smp_dict = {}\n",
    "        for idx, label in enumerate(labels_list):\n",
    "            if label not in self.label_smp_dict:\n",
    "                self.label_smp_dict[label] = []\n",
    "            self.label_smp_dict[label].append({\n",
    "                \"audio\": audio_feats_list[idx],\n",
    "                \"video\": video_feats_list[idx],\n",
    "                \"text\": text_list[idx],\n",
    "                \"label\": labels_list[idx],\n",
    "            })\n",
    "        self.aug = False\n",
    "        self.aug_len = 0\n",
    "        self.sometimes = lambda aug: va.Sometimes(aug_prob, aug) # Used to apply augmentor with 50% probability\n",
    "        \n",
    "        self.transform_list = [\n",
    "            self.sometimes(va.Salt()),\n",
    "            self.sometimes(va.Pepper()),\n",
    "            self.sometimes(va.RandomShear(0.2, 0.2)),\n",
    "            self.sometimes(va.HorizontalFlip()),\n",
    "            self.sometimes(va.VerticalFlip()),\n",
    "            self.sometimes(va.RandomRotate(30)),\n",
    "            self.sometimes(va.GaussianBlur(0.8)),\n",
    "            self.sometimes(va.ElasticTransformation(0.2,0.2)),\n",
    "            self.sometimes(va.PiecewiseAffineTransform(20,10,0.5)),\n",
    "        ]\n",
    "        \n",
    "\n",
    "    def __upsample__(self, origin_smp_list, smp_length, k=None):\n",
    "        smpled_list = origin_smp_list\n",
    "        for idx in tqdm(range(smp_length-len(origin_smp_list))):\n",
    "            seq = va.Sequential(random.choices(self.transform_list, k=k))\n",
    "            smp = random.choice(origin_smp_list)\n",
    "            vid = smp[\"video\"].squeeze()\n",
    "            vid = [cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB).astype(np.uint8) for frame in vid]\n",
    "            vid = np.stack(vid)\n",
    "            video_aug = seq(vid)\n",
    "            video_aug = [cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_RGB2GRAY).astype(np.uint8) for frame in video_aug]\n",
    "            video_aug = np.stack(video_aug)\n",
    "            video_aug = video_aug[np.newaxis, np.newaxis]\n",
    "            \n",
    "            smpled_list.append({\n",
    "                \"video\": video_aug,\n",
    "                \"audio\": smp['audio'],\n",
    "                \"text\": smp['text'],\n",
    "                \"label\": smp['label'],\n",
    "            })\n",
    "        return smpled_list\n",
    "            \n",
    "        \n",
    "    \n",
    "    def __aug__(self, niters=2, nchoice=2, isaug=True):\n",
    "        self.aug_label_smp_dict = {}\n",
    "        self.aug_smps = []\n",
    "        if isaug:\n",
    "            print([len(v) for k,v in self.label_smp_dict.items()])\n",
    "            smp_size = max([len(v) for k,v in self.label_smp_dict.items()])*(niters+1)\n",
    "            for k, v in self.label_smp_dict.items():\n",
    "                print(smp_size, len(v))\n",
    "                upsmped = self.__upsample__(v, smp_size, nchoice)\n",
    "                self.aug_label_smp_dict[k] = upsmped\n",
    "                self.aug_smps += upsmped\n",
    "                \n",
    "            self.aug = True\n",
    "            print([len(v) for k,v in self.aug_label_smp_dict.items()])\n",
    "        else:\n",
    "            print([len(v) for k,v in self.label_smp_dict.items()])\n",
    "            for k, v in self.label_smp_dict.items():\n",
    "                self.aug_label_smp_dict[k] = v\n",
    "                self.aug_smps += v\n",
    "            self.aug = True\n",
    "            print([len(v) for k,v in self.aug_label_smp_dict.items()])\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.aug_smps)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_feats = self.aug_smps[idx][\"audio\"]\n",
    "        video_feats = self.aug_smps[idx][\"video\"]/255\n",
    "        padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "        return {\n",
    "            \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "            \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "            \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "            \"text\": self.aug_smps[idx][\"text\"],\n",
    "            \"labels\": self.aug_smps[idx][\"label\"]\n",
    "        }\n",
    "\n",
    "# class VidaugDataset(Dataset):\n",
    "    \n",
    "#     def collate(self, audio, video, max_size=500):\n",
    "#         padded_audio = pad_sequence([torch.tensor(a.squeeze()) for a in audio]+[torch.empty(500, 104)], batch_first=True)[:-1]\n",
    "#         padded_video = pad_sequence([v.squeeze().clone().detach() for v in video]+[torch.empty(500,88,88)], batch_first=True)[:-1, np.newaxis, : ,:,:]\n",
    "#         mask = torch.zeros_like(padded_audio)\n",
    "#         mask[padded_audio != 0] = 1\n",
    "#         return padded_audio, padded_video, mask\n",
    "    \n",
    "    \n",
    "#     def __init__(self, audio_feats_list, \n",
    "#                  video_feats_list, \n",
    "#                  text_list, \n",
    "#                  labels_list):\n",
    "#         self.audio_feats_list = audio_feats_list\n",
    "#         self.video_feats_list = video_feats_list\n",
    "#         self.text_list = text_list\n",
    "#         self.labels_list = labels_list\n",
    "    \n",
    "#         print(len(self.audio_feats_list))\n",
    "#         print(len(self.video_feats_list))\n",
    "#         print(len(self.text_list))\n",
    "#         print(len(self.labels_list))\n",
    "        \n",
    "#         self.origin_len = len(self.labels_list)\n",
    "#         self.aug_len = 0\n",
    "\n",
    "    \n",
    "    \n",
    "#     def __aug__(self, niters=2, aug_prob=0.3, k=None):\n",
    "#         sometimes = lambda aug: va.Sometimes(aug_prob, aug) # Used to apply augmentor with 50% probability\n",
    "        \n",
    "#         transform_list = [\n",
    "#             # sometimes(va.InvertColor()),\n",
    "#             sometimes(va.Salt()),\n",
    "#             sometimes(va.Pepper()),\n",
    "#             sometimes(va.RandomShear(0.2, 0.2)),\n",
    "#             sometimes(va.HorizontalFlip()),\n",
    "#             sometimes(va.VerticalFlip()),\n",
    "#             sometimes(va.RandomRotate(30)),\n",
    "#             sometimes(va.GaussianBlur(0.8)),\n",
    "#             sometimes(va.ElasticTransformation(0.2,0.2)),\n",
    "#             sometimes(va.PiecewiseAffineTransform(20,10,0.5)),\n",
    "#         ]\n",
    "        \n",
    "        \n",
    "#         self.aug_audio_feats_list = []\n",
    "#         self.aug_video_feats_list = []\n",
    "#         self.aug_text_list = []\n",
    "#         self.aug_labels_list = []\n",
    "        \n",
    "#         for smp_id in tqdm(range(len(self.video_feats_list))):\n",
    "#             for i in range(niters):\n",
    "#                 if k is None:\n",
    "#                     seq = va.Sequential(random.choices(transform_list, \n",
    "#                                                    k=random.choice(range(len(transform_list)))))        \n",
    "#                 else:\n",
    "#                     seq = va.Sequential(random.choices(transform_list, \n",
    "#                                                    k=k))\n",
    "#                 vid = self.video_feats_list[smp_id].squeeze()\n",
    "#                 # change to color \n",
    "#                 vid = [cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB).astype(np.uint8) for frame in vid]\n",
    "#                 vid = np.stack(vid)\n",
    "#                 video_aug = seq(vid)\n",
    "#                 # print(video_aug[0].shape)\n",
    "#                 video_aug = [cv2.cvtColor(frame.astype(np.float32), cv2.COLOR_RGB2GRAY).astype(np.uint8) for frame in video_aug]\n",
    "#                 video_aug = np.stack(video_aug)\n",
    "                \n",
    "#                 # transform = avhubert_utils.Compose([\n",
    "#                 #   avhubert_utils.Normalize(0.0, 255.0),\n",
    "#                 #   avhubert_utils.CenterCrop((88, 88)),\n",
    "#                 #   avhubert_utils.Normalize(0.421, 0.165)])\n",
    "#                 # video_aug = transform(video_aug)[np.newaxis, np.newaxis]\n",
    "\n",
    "#                 video_aug = (video_aug/255)[np.newaxis, np.newaxis]\n",
    "\n",
    "                \n",
    "#                 video_aug = torch.tensor(video_aug)\n",
    "#                 self.aug_audio_feats_list.append(self.audio_feats_list[smp_id])\n",
    "#                 self.aug_video_feats_list.append(video_aug)\n",
    "#                 self.aug_text_list.append(self.text_list[smp_id])\n",
    "#                 self.aug_labels_list.append(self.labels_list[smp_id])\n",
    "                \n",
    "#         self.aug_len = len(self.aug_labels_list)\n",
    "                \n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.origin_len + self.aug_len\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         if idx < self.origin_len:\n",
    "#             audio_feats = self.audio_feats_list[idx]\n",
    "#             video_feats = self.video_feats_list[idx]\n",
    "#             padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "#             return {\n",
    "#                 \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "#                 \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "#                 \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "#                 \"text\": self.text_list[idx],\n",
    "#                 \"labels\": self.labels_list[idx]\n",
    "#             }\n",
    "#         else:\n",
    "#             idx = idx - self.origin_len\n",
    "#             audio_feats = self.aug_audio_feats_list[idx]\n",
    "#             video_feats = self.aug_video_feats_list[idx]\n",
    "#             padded_audio, padded_video, padding_mask = self.collate([audio_feats], [torch.tensor(video_feats)])\n",
    "#             return {\n",
    "#                 \"padding_mask\": padding_mask[0][:500, :].float(),\n",
    "#                 \"audio\": padded_audio[0][:500, :].T.float(),\n",
    "#                 \"video\": padded_video[0][:, :500, :, :].float(),\n",
    "#                 \"text\": self.aug_text_list[idx],\n",
    "#                 \"labels\": self.aug_labels_list[idx]\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f90f1e8f-2234-4722-a4d0-535048f8077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feats_list = mmser_ds.audio_feats_list\n",
    "video_feats_list = mmser_ds.video_feats_list\n",
    "text_list = list(meta_df_[\"transcript\"])\n",
    "labels_list = list(meta_df_[\"emotion_id\"])\n",
    "\n",
    "del mmser_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fed7638-bfe1-4fe9-b11a-ef464dcfc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = sess_dict['Ses03']\n",
    "test_indices = sess_dict['Ses04']\n",
    "train_indices = list(all_indices-set(val_indices)-set(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543c179e-1903-4419-a2fd-c33e9e9c0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in train_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in train_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in train_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in train_indices]\n",
    ")\n",
    "\n",
    "val_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in val_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in val_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in val_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in val_indices]\n",
    ")\n",
    "\n",
    "test_ds = VidaugDataset(\n",
    "    [item.detach().numpy() for i, item in enumerate(audio_feats_list) if i in test_indices],\n",
    "    [item.detach().numpy() for i, item in enumerate(video_feats_list) if i in test_indices],\n",
    "    [item for i, item in enumerate(text_list) if i in test_indices],\n",
    "    [item for i, item in enumerate(labels_list) if i in test_indices]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c1dc6d-8d9e-4015-9fa4-0b9893a25c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0, 3.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de096d1d-6742-4cb2-aff1-015943b0b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1130, 536, 636, 1047]\n",
      "3390 1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2260/2260 [01:35<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2854/2854 [02:26<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2754/2754 [02:53<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 2343/2343 [01:46<00:00, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3390, 3390, 3390, 3390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds.__aug__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "012878dd-d857-4742-9436-f714036d0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320, 286, 305, 240]\n",
      "[320, 286, 305, 240]\n",
      "[327, 143, 303, 258]\n",
      "[327, 143, 303, 258]\n"
     ]
    }
   ],
   "source": [
    "val_ds.__aug__(isaug=False)\n",
    "test_ds.__aug__(isaug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a7c46a-08eb-45dc-8b11-f0bbbdb6d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13560\n",
      "1151\n",
      "1031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500, 88, 88])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(val_ds))\n",
    "print(len(test_ds))\n",
    "train_ds[0][\"video\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573929b",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be847c2-4282-4906-8add-40136adb8012",
   "metadata": {},
   "source": [
    "API: 2999b8f99f0f62b4f64c48a1c8be9a16945183e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2329893c-3888-4ff6-b37e-b1b538afb36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: pre-trained w/o fine-tuning\n"
     ]
    }
   ],
   "source": [
    "from avhubert_classifier import AVHUBERTClassifier\n",
    "user_dir = \"/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"/data/chuak/mmser/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdb496-80eb-43b3-afaf-5bdc2f9cac3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfde834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmser\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/wandb/run-20231217_165201-gamfee8b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/gamfee8b' target=\"_blank\">silvery-snowball-3</a></strong> to <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video' target=\"_blank\">https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/gamfee8b' target=\"_blank\">https://wandb.ai/mmser/multi_modal_ser-finetune_encoder_audio_video_src_multi_modal_ser_finetune_encoder_audio_video/runs/gamfee8b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "# avhubert_classifier = AVHUBERTClassifier(model, 768, 256)\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 64)\n",
    "for param in avhubert_classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "wandb.init()\n",
    "train_set = train_ds\n",
    "val_set = val_ds\n",
    "test_set = test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be934063-6dd4-4911-af28-d52cd19a3cb2",
   "metadata": {},
   "source": [
    "### Change resnet weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb6c8673-22c3-49ff-b504-ad5e3fce69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "# avhubert_classifier.encoder.feature_extractor_video.resnet = InceptionResnetV1(pretrained='vggface2')\n",
    "avhubert_classifier = avhubert_classifier.to(device)\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 32)\n",
    "\n",
    "facenet_res = InceptionResnetV1(pretrained='vggface2')\n",
    "faceNetBlock = facenet_res\n",
    "avhubert_classifier.encoder.feature_extractor_video.resnet.trunk = faceNetBlock\n",
    "avhubert_classifier.encoder.feature_extractor_video.resnet.frontend3D =nn.Conv3d(1, 3, \n",
    "                                      kernel_size=(5, 7, 7), \n",
    "                                      stride=(1, 1, 1), \n",
    "                                      padding=(2, 3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "341a9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=os.path.join(\"check_pts\", \"AVHUBERT\", datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\"))\n",
    "\n",
    "training_args = TrainingArguments(output_dir,report_to=\"wandb\")\n",
    "training_args.remove_unused_columns=False\n",
    "training_args.per_device_train_batch_size=2\n",
    "training_args.per_device_eval_batch_size=2\n",
    "training_args.logging_steps = int(1000/training_args.per_device_train_batch_size/8)\n",
    "training_args.eval_steps = int(1000/training_args.per_device_train_batch_size/8)\n",
    "training_args.evaluation_strategy=\"steps\" \n",
    "training_args.logging_strategy=\"steps\"\n",
    "training_args.load_best_model_at_end=True,\n",
    "training_args.save_strategy = \"no\"\n",
    "training_args.learning_rate=5e-4\n",
    "training_args.num_train_epochs=7\n",
    "training_args.metric_for_best_model = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27ade4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from avhubert_trainer import CustomTrainer , compute_metrics\n",
    "from transformers import EarlyStoppingCallback, TrainerCallback, TrainerState\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=avhubert_classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6778b05-02f5-4598-86ed-2a69d88a1323",
   "metadata": {},
   "source": [
    "##### Gradual Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7a1b316-8b55-4e88-bbf0-32e4d8e271dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreezingCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, freeze_encoder_epochs: int):\n",
    "        self.freeze_encoder_epochs = freeze_encoder_epochs\n",
    "\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        print(state.epoch, self.freeze_encoder_epochs)\n",
    "        model = kwargs[\"model\"]\n",
    "        if state.epoch >= self.freeze_encoder_epochs:\n",
    "            print(\"=\"*10, \"Freezing\", \"=\"*10)\n",
    "            for param in model.encoder.feature_extractor_video.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13dec778-5859-43c9-bc0c-90dcd24bac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90bf04a5-0861-4dba-917b-3a23fdfff97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing_callback = FreezingCallback(3)\n",
    "# trainer.add_callback(freezing_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f342fd-5ad9-47c6-9858-1b6b721a1f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='5936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 129/5936 59:54 < 45:38:54, 0.04 it/s, Epoch 0.15/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wa</th>\n",
       "      <th>Ua</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.399800</td>\n",
       "      <td>1.430543</td>\n",
       "      <td>0.248480</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.098908</td>\n",
       "      <td>0.248480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.398200</td>\n",
       "      <td>1.413233</td>\n",
       "      <td>0.248480</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.098908</td>\n",
       "      <td>0.248480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chuak/mmser/src/multi_modal_ser/finetune_encoder/audio_video/avhubert_trainer.py:34: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\")\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73117560-10f3-484d-813e-af68d15761cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53544a-76b0-4ab5-b22b-f4979adfa195",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(faceNetBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0829d84-db7b-46f5-9363-8cf7e5d57cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11186688"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(avhubert_classifier.encoder.feature_extractor_video.resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2bba2c6-d14c-47b4-a81b-c4c56d3ef80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86cada-d000-4da5-bff4-09d1a5254029",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = trainer.predict(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f14d3-0bbc-4719-9d33-51ac39db7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c74dd-72b3-46d4-8e41-94309b0d2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_labels = val_preds.predictions.argmax(axis=1)\n",
    "true_labels = val_preds.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b34e23-f64d-41ff-83ba-c1117cdea3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_labels[10:15])\n",
    "print(true_labels[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e003f-bf5b-4342-a795-794a7fa0cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33504e25-c1e4-4a04-b6b6-888cd94d7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(true_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea3c3b-cc75-47a4-b06d-3f90bd720484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1832c-d791-4271-8f75-b9370915e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d2156-d8b1-4b4e-821e-24a4e8df145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(true_labels, pred_labels, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0c521-e2a9-4b2f-8e27-b7e0563ace08",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "output = loss(torch.tensor(val_preds.predictions), torch.tensor(true_labels).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52c24b-edbf-4784-8e69-eb26c806a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef31267",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "test_result = trainer.predict(test_set).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40875ee9-9164-4545-b53f-dc2a9e210777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83889a1d-fb15-4e01-9690-307e0650526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da509cb2-d2af-4235-b631-337cb7964263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163a9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00358b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967ebfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
