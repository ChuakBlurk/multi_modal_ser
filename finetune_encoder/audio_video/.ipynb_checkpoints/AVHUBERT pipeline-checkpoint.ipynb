{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d4075b",
   "metadata": {},
   "source": [
    "### Prepare Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6c4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/av_hubert.git\n",
    "\n",
    "# %cd av_hubert\n",
    "# !git submodule init\n",
    "# !git submodule update\n",
    "# !pip install scipy\n",
    "# !pip install sentencepiece\n",
    "# !pip install python_speech_features\n",
    "# !pip install scikit-video\n",
    "\n",
    "# %cd fairseq\n",
    "# !python -m pip install ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e231ede0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\university\\FYT\\repos\\multi_modal_ser\\finetune_encoder\\audio_video\\av_hubert\\avhubert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1 (default, Oct 28 2018, 08:39:03) [MSC v.1912 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "%cd E:/university/FYT/repos/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"E:/university/FYT/repos/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq\")\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "import cv2\n",
    "import tempfile\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import utils as avhubert_utils\n",
    "from argparse import Namespace\n",
    "from IPython.display import HTML\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import logfbank\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.version)\n",
    "import torch.nn as nn\n",
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7624284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacker(feats, stack_order):\n",
    "    \"\"\"\n",
    "    Concatenating consecutive audio frames\n",
    "    Args:\n",
    "    feats - numpy.ndarray of shape [T, F]\n",
    "    stack_order - int (number of neighboring frames to concatenate\n",
    "    Returns:\n",
    "    feats - numpy.ndarray of shape [T', F']\n",
    "    \"\"\"\n",
    "    feat_dim = feats.shape[1]\n",
    "    if len(feats) % stack_order != 0:\n",
    "        res = stack_order - len(feats) % stack_order\n",
    "        res = np.zeros([res, feat_dim]).astype(feats.dtype)\n",
    "        feats = np.concatenate([feats, res], axis=0)\n",
    "    feats = feats.reshape((-1, stack_order, feat_dim)).reshape(-1, stack_order*feat_dim)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1442ff",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15addb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/vsr/base_vox_433h.pt -O E:/check_pts/avhubert.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edf8e1",
   "metadata": {},
   "source": [
    "### Build Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da14d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: fine-tuned\n"
     ]
    }
   ],
   "source": [
    "user_dir = \"E:/university/FYT/repos/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"E:/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2d7d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 104)\n",
      "torch.Size([1, 1, 186, 88, 88])\n"
     ]
    }
   ],
   "source": [
    "smp_id = \"Ses01F_impro05_M017\"\n",
    "video_path = \"E:/datasets/preprocessed/face_raw/{}.mp4\".format(smp_id)\n",
    "audio_path = \"E:/datasets/preprocessed/spectrogram/raw/{}.wav\".format(smp_id)\n",
    "\n",
    "# Load Video\n",
    "# Mute transform first\n",
    "transform = avhubert_utils.Compose([\n",
    "  avhubert_utils.Normalize(0.0, 255.0),\n",
    "  avhubert_utils.CenterCrop((task.cfg.image_crop_size, task.cfg.image_crop_size)),\n",
    "  avhubert_utils.Normalize(task.cfg.image_mean, task.cfg.image_std)])\n",
    "\n",
    "frames = avhubert_utils.load_video(video_path)\n",
    "# frames = transform(frames)\n",
    "frames = torch.FloatTensor(frames).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "video_feats = frames\n",
    "\n",
    "# Load Audio\n",
    "sample_rate, wav_data = wavfile.read(audio_path)\n",
    "in_features = model.feature_extractor_audio.proj.in_features\n",
    "assert sample_rate == 16_000 and len(wav_data.shape) == 1\n",
    "audio_feats = logfbank(wav_data, samplerate=sample_rate).astype(np.float32) # [T, F]\n",
    "audio_feats = stacker(audio_feats, in_features//26) # [T/stack_order_audio, F*stack_order_audio]\n",
    "\n",
    "# Match Audio Video\n",
    "print(audio_feats.shape)\n",
    "print(video_feats.shape)\n",
    "\n",
    "diff = audio_feats.shape[0] - video_feats.shape[2]\n",
    "if diff < 0:\n",
    "    audio_feats = np.concatenate([audio_feats, np.zeros([-diff, audio_feats.shape[-1]], dtype=audio_feats.dtype)])\n",
    "elif diff > 0:\n",
    "    audio_feats = audio_feats[:-diff]\n",
    "\n",
    "import torch.nn.functional as F\n",
    "audio_feats = torch.from_numpy(audio_feats.astype(np.float32)).T\n",
    "audio_feats = F.layer_norm(audio_feats, audio_feats.shape[1:])\n",
    "audio_feats = audio_feats.unsqueeze(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa7321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video feature shape: torch.Size([186, 768])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Specify output_layer if you want to extract feature of an intermediate layer\n",
    "    feature, _ = model.extract_finetune(source={'video': video_feats , \n",
    "                                                'audio': audio_feats}, padding_mask=None, output_layer=None)\n",
    "    feature = feature.squeeze(dim=0) \n",
    "print(f\"Video feature shape: {feature.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c90a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Model Standalone Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4e65941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "AUDIORATE=16000\n",
    "class MMSERDataset(Dataset):\n",
    "    \"\"\"multi model ser dataset.\"\"\"\n",
    "    \n",
    "    def stacker(self, feats, stack_order):\n",
    "        \"\"\"\n",
    "        Concatenating consecutive audio frames\n",
    "        Args:\n",
    "        feats - numpy.ndarray of shape [T, F]\n",
    "        stack_order - int (number of neighboring frames to concatenate\n",
    "        Returns:\n",
    "        feats - numpy.ndarray of shape [T', F']\n",
    "        \"\"\"\n",
    "        feat_dim = feats.shape[1]\n",
    "        if len(feats) % stack_order != 0:\n",
    "            res = stack_order - len(feats) % stack_order\n",
    "            res = np.zeros([res, feat_dim]).astype(feats.dtype)\n",
    "            feats = np.concatenate([feats, res], axis=0)\n",
    "        feats = feats.reshape((-1, stack_order, feat_dim)).reshape(-1, stack_order*feat_dim)\n",
    "        return feats\n",
    "        \n",
    "    def __load_label__(self, cutmap_path):\n",
    "        sheet_df = pd.DataFrame()\n",
    "        for ses in range(1, 6):\n",
    "            extractionmapPATH = cutmap_path + \\\n",
    "                str(ses)+'.xlsx'\n",
    "            xl = pd.ExcelFile(extractionmapPATH)\n",
    "            sheets = xl.sheet_names\n",
    "            for sheet in sheets:\n",
    "                sheet_df = pd.concat([sheet_df, xl.parse(sheet)])\n",
    "        self.df_ = sheet_df\n",
    "        \n",
    "        # remove samples not agreed\n",
    "        self.df_ = pd.merge(self.df_, self.df_text, on=[\"smp_id\"])\n",
    "        self.df_[\"emotion_id\"] = self.df_[\"emotion\"].map(self.emo2id)\n",
    "        self.df_ = self.df_[self.df_[\"emotion_id\"].notna()].reset_index(drop=True)\n",
    "        self.df_[\"session\"] = self.df_[\"smp_id\"].apply(lambda x: x.split(\"_\")[0])\n",
    "        self.df_ = self.df_[self.df_[\"smp_id\"].str.startswith(\"Ses01F_impro\")].reset_index(drop=True)\n",
    "        \n",
    "    def __load_text__(self, text_path):\n",
    "        self.df_text = pd.read_csv(text_path)\n",
    "        pass\n",
    "    \n",
    "    def __load_audio__(self, fn_path):\n",
    "        self.fn_list = list(self.df_[\"smp_id\"])\n",
    "        self.raw_list = []\n",
    "        for fn in self.fn_list:\n",
    "            self.raw_list.append(wavfile.read(os.path.join(fn_path, fn)+'.wav')[1])\n",
    "    \n",
    "    def __load_video__(self, idx):\n",
    "        frames = avhubert_utils.load_video(os.path.join(self.video_path, idx+\".mp4\"))\n",
    "#         transform = avhubert_utils.Compose([\n",
    "#           avhubert_utils.Normalize(0.0, 255.0),\n",
    "#           avhubert_utils.CenterCrop((task.cfg.image_crop_size, task.cfg.image_crop_size)),\n",
    "#           avhubert_utils.Normalize(task.cfg.image_mean, task.cfg.image_std)])\n",
    "        # frames = transform(frames)\n",
    "        frames = torch.FloatTensor(frames).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "        video_feats = frames\n",
    "        return video_feats\n",
    "    \n",
    "    def __init__(self, \n",
    "                 fn_path, \n",
    "                 cutmap_path, \n",
    "                 text_path, \n",
    "                 video_path, \n",
    "                 emo2id,\n",
    "                 audio_in_features = 104):\n",
    "        \n",
    "        self.emo2id = emo2id\n",
    "        self.audio_in_features = audio_in_features\n",
    "        self.video_path = video_path\n",
    "        self.__load_text__(text_path)\n",
    "        self.__load_label__(cutmap_path)\n",
    "        self.__load_audio__(fn_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df_.shape[0]\n",
    "    \n",
    "    def __getsingle__(self, idx):\n",
    "        raw_audio = self.raw_list[idx]\n",
    "        video_feats = self.__load_video__(self.fn_list[idx])\n",
    "        audio_feats = logfbank(raw_audio, samplerate=AUDIORATE).astype(np.float32) # [T, F]\n",
    "        audio_feats = self.stacker(audio_feats, self.audio_in_features//26) # [T/stack_order_audio, F*stack_order_audio]\n",
    "\n",
    "        diff = audio_feats.shape[0] - video_feats.shape[2]\n",
    "        if diff < 0:\n",
    "            audio_feats = np.concatenate([audio_feats, np.zeros([-diff, audio_feats.shape[-1]], dtype=audio_feats.dtype)])\n",
    "        elif diff > 0:\n",
    "            audio_feats = audio_feats[:-diff]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            audio_feats = torch.from_numpy(audio_feats.astype(np.float32)).T\n",
    "            audio_feats = F.layer_norm(audio_feats, audio_feats.shape[1:])\n",
    "            audio_feats = audio_feats.unsqueeze(dim=0)\n",
    "        return audio_feats, video_feats\n",
    "    \n",
    "    def collate(self, audio, video, max_size=500):\n",
    "        padded_audio = pad_sequence([a.T.squeeze() for a in audio], batch_first=True)\n",
    "        padded_video = pad_sequence([v.squeeze() for v in video], batch_first=True)[:, np.newaxis, : ,:,:]\n",
    "        mask = torch.zeros_like(padded_audio)\n",
    "        mask[padded_audio != 0] = 1\n",
    "        return padded_audio, padded_video, mask\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            ret_dict = {}\n",
    "            for key in self.__getitem__(0).keys():\n",
    "                ret_dict[key] = [self.__getitem__(i)[key] for i in range(*idx.indices(len(self)))]\n",
    "            \n",
    "            padded_audio, padded_video, padding_mask = self.collate(ret_dict[\"audio\"], ret_dict[\"video\"])\n",
    "            ret_dict[\"padding_mask\"] = padding_mask\n",
    "            ret_dict[\"audio\"] = padded_audio.transpose(1, 2)\n",
    "            ret_dict[\"video\"] = padded_video\n",
    "            return ret_dict\n",
    "        else:\n",
    "            audio_feats, video_feats = self.__getsingle__(idx)\n",
    "\n",
    "            return {\n",
    "                \"sess\": list(self.df_[\"session\"])[idx],\n",
    "                \"fn\": self.fn_list[idx],\n",
    "                \"audio\": audio_feats,\n",
    "                \"video\": video_feats,\n",
    "                \"text\": list(self.df_[\"transcript\"])[idx],\n",
    "                \"labels\": list(self.df_[\"emotion_id\"])[idx]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e339c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmser_ds = torch.load(\"E:/datasets/preprocessed/dataset/avhubert_ds.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7171d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 104, 118])\n",
      "torch.Size([2, 1, 118, 88, 88])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:100: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3281.)\n"
     ]
    }
   ],
   "source": [
    "print(mmser_ds[2:4]['audio'].shape)\n",
    "print(mmser_ds[2:4]['video'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e62f9089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2714,  0.0107,  0.0076,  ..., -0.0071,  0.1340, -0.1701],\n",
       "          [-0.0149, -0.0350, -0.0869,  ..., -0.2547,  0.2382, -0.0165],\n",
       "          [ 0.1174, -0.0280, -0.0990,  ..., -0.3338,  0.2365,  0.0659],\n",
       "          ...,\n",
       "          [ 0.0875,  0.1732,  0.0196,  ..., -0.3151,  0.0981,  0.0563],\n",
       "          [-0.0360,  0.1825,  0.1498,  ..., -0.2829,  0.1447,  0.0310],\n",
       "          [-0.2531,  0.1423,  0.2568,  ..., -0.2468,  0.1728,  0.0075]],\n",
       " \n",
       "         [[-0.2578,  0.0118,  0.0052,  ..., -0.0217,  0.1347, -0.1596],\n",
       "          [-0.0543, -0.0410, -0.0668,  ..., -0.2334,  0.2330, -0.0081],\n",
       "          [ 0.1206, -0.0092, -0.0708,  ..., -0.3427,  0.2359,  0.1033],\n",
       "          ...,\n",
       "          [ 0.1035,  0.1580,  0.0315,  ..., -0.3325,  0.0977,  0.0731],\n",
       "          [-0.0179,  0.1688,  0.1578,  ..., -0.2980,  0.1469,  0.0383],\n",
       "          [-0.2413,  0.1357,  0.2667,  ..., -0.2520,  0.1722,  0.0120]],\n",
       " \n",
       "         [[-0.2833, -0.0067, -0.0087,  ...,  0.0066,  0.1519, -0.1971],\n",
       "          [-0.0400, -0.0477, -0.1020,  ..., -0.2490,  0.2408, -0.1001],\n",
       "          [ 0.1041, -0.0472, -0.1261,  ..., -0.3474,  0.2430,  0.0006],\n",
       "          ...,\n",
       "          [ 0.0490,  0.1524, -0.0342,  ..., -0.3322,  0.1314,  0.0702],\n",
       "          [-0.0668,  0.1694,  0.0902,  ..., -0.3064,  0.1689,  0.0464],\n",
       "          [-0.2668,  0.1301,  0.2315,  ..., -0.2691,  0.2000,  0.0060]],\n",
       " \n",
       "         [[-0.2710, -0.0179, -0.0336,  ..., -0.0090,  0.1723, -0.1936],\n",
       "          [-0.0225, -0.0638, -0.1280,  ..., -0.2914,  0.2768, -0.0733],\n",
       "          [ 0.1167, -0.0400, -0.1464,  ..., -0.3722,  0.2687,  0.0235],\n",
       "          ...,\n",
       "          [ 0.1661,  0.1368, -0.0439,  ..., -0.4706,  0.1339,  0.0594],\n",
       "          [ 0.0237,  0.1361, -0.0257,  ..., -0.4433,  0.1648, -0.0090],\n",
       "          [-0.2804,  0.1271,  0.1385,  ..., -0.3418,  0.1874,  0.0017]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "AUDIORATE = 16000\n",
    "\n",
    "outputs = model.extract_finetune(mmser_ds[:4])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fb3b7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 118, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b934a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = mmser_ds[:4][\"padding_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fabec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_padding_mask(\n",
    "        features: torch.Tensor, padding_mask: torch.Tensor,\n",
    "    ):\n",
    "        extra = padding_mask.size(1) % features.size(1)\n",
    "        if extra > 0:\n",
    "            padding_mask = padding_mask[:, :-extra]\n",
    "        padding_mask = padding_mask.view(\n",
    "            padding_mask.size(0), features.size(1), -1\n",
    "        )\n",
    "        padding_mask = padding_mask.all(-1)\n",
    "        return padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3b0e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "forwarded_attention_mask = forward_padding_mask(outputs[0], attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb06072",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9da70288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AVHUBERTClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, hidden_size, proj_size, num_labels=4):\n",
    "        super(AVHUBERTClassifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.num_labels = num_labels\n",
    "        self.hidden_size = hidden_size\n",
    "        self.proj_size = proj_size\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        self.projector = nn.Linear(self.hidden_size, self.proj_size)\n",
    "        self.classifier = nn.Linear(self.proj_size, num_labels)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_values\n",
    "    ):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.encoder.extract_finetune(\n",
    "                input_values\n",
    "            )\n",
    "            hidden_states = outputs[0]\n",
    "        \n",
    "        hidden_states = self.projector(hidden_states)\n",
    "        attention_mask = input_values[\"padding_mask\"]\n",
    "        padding_mask = forward_padding_mask(hidden_states, attention_mask)\n",
    "        hidden_states[~padding_mask] = 0.0\n",
    "        pooled_output = hidden_states.sum(dim=1) / padding_mask.sum(dim=1).view(-1, 1)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return {\"logits\":logits}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95d16866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[-0.0676, -0.0648, -0.0106, -0.1240],\n",
       "         [-0.0886, -0.0630, -0.0200, -0.1239],\n",
       "         [-0.0388, -0.0450, -0.0148, -0.1037],\n",
       "         [-0.0373, -0.0581, -0.0111, -0.1149]], grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = AVHUBERTClassifier(model, 768, 256, mmser_ds.df_[\"emotion_id\"].nunique())\n",
    "classifier(mmser_ds[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eadf7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ds(sess_id):\n",
    "    train_size = int(len(sess_ds[sess_id+\"_train\"])*0.75)\n",
    "    val_size = len(sess_ds[sess_id+\"_train\"])-train_size\n",
    "    train_set, val_set = torch.utils.data.random_split(sess_ds[sess_id+\"_train\"], [train_size, val_size])\n",
    "    test_set = sess_ds[sess_id+\"_test\"]\n",
    "\n",
    "    print(\"Train Samples:\", len(train_set))\n",
    "    print(\"Val Samples:\", len(val_set))\n",
    "    print(\"Test Samples:\", len(test_set))\n",
    "    \n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac2374d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 180\n",
      "Val Samples: 61\n",
      "Test Samples: 241\n"
     ]
    }
   ],
   "source": [
    "meta_df_ = mmser_ds.df_\n",
    "sess_dict = meta_df_.groupby(\"session\").groups\n",
    "all_indices = set(meta_df_.index.tolist())\n",
    "sess_ds = {}\n",
    "for sess in sess_dict:\n",
    "#     sess_ds[sess+\"_train\"] = Subset(mmser_ds, \n",
    "#                                     indices=list(all_indices-set(sess_dict[sess])))\n",
    "    sess_ds[sess+\"_test\"] = Subset(mmser_ds, \n",
    "                                    indices=sess_dict[sess])\n",
    "    sess_ds[sess+\"_train\"] = Subset(mmser_ds, \n",
    "                                    indices=sess_dict[sess])\n",
    "    \n",
    "    \n",
    "    \n",
    "SESS_ID = list(sess_dict.keys())[0]\n",
    "train_set, val_set, test_set = build_ds(SESS_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b53bf38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\").type(torch.LongTensor).to(device)\n",
    "        \n",
    "        input_values = inputs[\"input_values\"].to(device).to(torch.float32)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device).to(torch.float32)\n",
    "        outputs = model(input_values, \n",
    "                       attention_mask)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss() \n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "def weighted_acc(y_true, y_pred):\n",
    "    return np.sum((np.array(y_pred).ravel() == np.array(y_true).ravel()))*1.0/len(y_true)\n",
    "    \n",
    "def unweighted_acc(y_true, y_pred):\n",
    "    y_true = np.array(y_true).ravel()\n",
    "    y_pred = np.array(y_pred).ravel()\n",
    "    classes = np.unique(y_true)\n",
    "    classes_accuracies = np.zeros(classes.shape[0])\n",
    "    for num, cls in enumerate(classes):\n",
    "        classes_accuracies[num] = weighted_acc(y_true[y_true == cls], y_pred[y_true == cls])\n",
    "    return np.mean(classes_accuracies)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds.predictions, eval_preds.label_ids\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    metric_f1 = load_metric(\"f1\")\n",
    "    metric_acc = load_metric(\"accuracy\")\n",
    "    logits, labels = eval_preds.predictions, eval_preds.label_ids\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    f1_ = metric_f1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    acc_ = metric_acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    \n",
    "    return {\"wa\":weighted_acc(labels, predictions), \n",
    "            \"ua\":unweighted_acc(labels, predictions),\n",
    "            \"f1\":f1_, \n",
    "            \"accuracy\":acc_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a40eb3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=os.path.join(\"avhubert\")\n",
    "\n",
    "training_args = TrainingArguments(output_dir,report_to=\"wandb\")\n",
    "training_args.remove_unused_columns=False\n",
    "training_args.per_device_train_batch_size=40\n",
    "training_args.per_device_eval_batch_size=20\n",
    "training_args.logging_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "training_args.eval_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "training_args.evaluation_strategy=\"steps\" \n",
    "training_args.logging_strategy=\"steps\"\n",
    "training_args.load_best_model_at_end=True,\n",
    "training_args.save_strategy = \"no\"\n",
    "training_args.learning_rate=1e-3\n",
    "training_args.num_train_epochs=50\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ff67c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\py37\\lib\\site-packages\\transformers\\optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "ename": "ServiceStartProcessError",
     "evalue": "The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServiceStartProcessError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10940\\4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1649\u001b[1;33m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1650\u001b[0m         )\n\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;31m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\transformers\\trainer_callback.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[1;34m(self, args, state, control)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mcontrol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_training_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_train_begin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\transformers\\trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[1;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[0meval_dataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m             )\n\u001b[0;32m    409\u001b[0m             \u001b[1;31m# A Callback can skip the return of `control` if it doesn't change it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\transformers\\integrations.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[1;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\transformers\\integrations.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m                 self._wandb.init(\n\u001b[0;32m    746\u001b[0m                     \u001b[0mproject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"WANDB_PROJECT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"huggingface\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m                     \u001b[1;33m**\u001b[0m\u001b[0minit_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m                 )\n\u001b[0;32m    749\u001b[0m             \u001b[1;31m# add config parameters (run may have been created manually)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1164\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[0mwi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m         \u001b[0mwi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mwi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0msetup_settings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"_disable_service\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_disable_service\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwandb_setup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msetup_settings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;31m# Make sure we have a logger setup (might be an early logger)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(settings)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0msettings\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSettings\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m ) -> Optional[\"_WandbSetup\"]:\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py\u001b[0m in \u001b[0;36m_setup\u001b[1;34m(settings, _reset)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0m_WandbSetup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mwl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_WandbSetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[0m_WandbSetup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0m_WandbSetup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_WandbSetup__WandbSetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pid, settings, environ)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mtracelog_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tracelog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py\u001b[0m in \u001b[0;36m_setup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0msweep_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msweep_param_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py\u001b[0m in \u001b[0;36m_setup_manager\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_disable_service\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwandb_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_teardown_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\wandb_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ManagerToken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_environment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_service\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"localhost\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mtransport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"tcp\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\service\\service.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_launch_server\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\service\\service.py\u001b[0m in \u001b[0;36m_launch_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_ports\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minternal_proc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                 \u001b[0m_sentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_startup_debug_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"wait_ports_done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_proc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minternal_proc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\analytics\\sentry.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self, exc)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;31m# this will messily add this \"reraise\" function to the stack trace,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;31m# but hopefully it's not too bad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_safe_noop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\service\\service.py\u001b[0m in \u001b[0;36m_launch_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_startup_debug_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"wait_ports\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_ports\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minternal_proc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0m_sentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\py37\\lib\\site-packages\\wandb\\sdk\\service\\service.py\u001b[0m in \u001b[0;36m_wait_for_ports\u001b[1;34m(self, fname, proc)\u001b[0m\n\u001b[0;32m    121\u001b[0m                     \u001b[1;34m\"You can override it with the `_executable` setting \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                     \u001b[1;34m\"or with the `WANDB__EXECUTABLE` environment variable.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                     \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m                 )\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mServiceStartProcessError\u001b[0m: The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environment variable."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163a9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
