{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d4075b",
   "metadata": {},
   "source": [
    "### Prepare Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041460cc-7376-4d29-b95d-156e4b21b530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install omegaconf==2.1.1\n",
    "# !pip install hydra-core==1.1.1\n",
    "# !pip install -U numpy==1.23.5\n",
    "# !apt-get update && apt-get install -y python3-opencv\n",
    "# !pip install opencv-python\n",
    "# !pip install scikit-image \n",
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install transformers[torch]\n",
    "# !pip install accelerate -U\n",
    "# !pip install wandb\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6c4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/av_hubert.git\n",
    "\n",
    "# %cd av_hubert\n",
    "# !git submodule init\n",
    "# !git submodule update\n",
    "# !pip install scipy\n",
    "# !pip install sentencepiece\n",
    "# !pip install python_speech_features\n",
    "# !pip install scikit-video\n",
    "\n",
    "# %cd fairseq\n",
    "# !pip install ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e231ede0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert\n",
      "3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "import cv2\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import sys\n",
    "sys.path.append(\"/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\")\n",
    "%cd /home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/\n",
    "import utils as avhubert_utils\n",
    "from argparse import Namespace\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128ecb29-946d-4fae-b806-17946ca63f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Sun Oct 22 11:24:10 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:53:00.0 Off |                  N/A |\n",
      "| 62%   46C    P8              44W / 300W |      5MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        On  | 00000000:8D:00.0 Off |                  N/A |\n",
      "| 36%   42C    P8              21W / 300W |      5MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1442ff",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15addb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/home/check_pts/\")\n",
    "# !wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/vsr/base_vox_433h.pt -O /home/check_pts/avhubert.pt\n",
    "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/clean-pretrain/base_vox_iter4.pt -O /home/check_pts/avhubert.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edf8e1",
   "metadata": {},
   "source": [
    "### Build Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da14d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: fine-tuned\n"
     ]
    }
   ],
   "source": [
    "user_dir = \"/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"/home/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7d434",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86df1ecf-343d-4464-824b-4adf070a8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e339c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_ds import AVHUBERTDataset\n",
    "mmser_ds = torch.load(\"/home/avhubert_ds2.pt\")\n",
    "mmser_ds.video_path = \"/home/face_raw/\"\n",
    "\n",
    "# outputs = model.extract_finetune(mmser_ds[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4043f023-01f6-4abc-aa9d-665b1ee7fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5531/5531 [08:25<00:00, 10.94it/s]\n"
     ]
    }
   ],
   "source": [
    "mmser_ds.cached = False\n",
    "mmser_ds.__cache__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb06072",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da70288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_classifier import AVHUBERTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d16866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[ 0.1050,  0.0140, -0.0034, -0.1027],\n",
       "         [ 0.1125,  0.0125,  0.0009, -0.0934],\n",
       "         [ 0.1207,  0.0199,  0.0044, -0.1207],\n",
       "         [ 0.1206,  0.0186, -0.0049, -0.1321]], grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = AVHUBERTClassifier(model, 768, 256, mmser_ds.df_[\"emotion_id\"].nunique())\n",
    "classifier(**mmser_ds[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d940a",
   "metadata": {},
   "source": [
    "### Build Train Test DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c429bfe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2948954732.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    sess =\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "meta_df_ = mmser_ds.df_\n",
    "mmser_ds.df_[\"bigsess\"] = mmser_ds.df_[\"session\"].apply(lambda x: x[:-1])\n",
    "sess_dict = mmser_ds.df_.groupby(\"bigsess\").groups\n",
    "all_indices = set(mmser_ds.df_.index.tolist())\n",
    "\n",
    "sess_ds = {}\n",
    "for i in range(1,6):\n",
    "    sess = \"Ses0{}\".format(i)\n",
    "    sess_val = \"Ses0{}\".format(i%5+1)\n",
    "    sess_ds[sess+\"_test\"] = Subset(mmser_ds, \n",
    "                                    indices=sess_dict[sess])\n",
    "    sess_ds[sess+\"_val\"] = Subset(mmser_ds, \n",
    "                                    indices=sess_dict[sess_val])\n",
    "    sess_ds[sess+\"_train\"] = Subset(mmser_ds, \n",
    "                                    indices=list(all_indices-set(sess_dict[sess])-set(sess_dict[sess_val])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eadf7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ds(sess_id):\n",
    "    train_size = int(len(sess_ds[sess_id+\"_train\"])*0.75)\n",
    "    val_size = len(sess_ds[sess_id+\"_train\"])-train_size\n",
    "    train_set, val_set = torch.utils.data.random_split(sess_ds[sess_id+\"_train\"], [train_size, val_size])\n",
    "    test_set = sess_ds[sess_id+\"_test\"]\n",
    "\n",
    "    print(\"Train Samples:\", len(train_set))\n",
    "    print(\"Val Samples:\", len(val_set))\n",
    "    print(\"Test Samples:\", len(test_set))\n",
    "    \n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573929b",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be847c2-4282-4906-8add-40136adb8012",
   "metadata": {},
   "source": [
    "API: 2999b8f99f0f62b4f64c48a1c8be9a16945183e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecfde834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Ses04M ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmser\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/wandb/run-20231022_113248-tshaz8f3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mmser/av_hubert/runs/tshaz8f3' target=\"_blank\">driven-sun-15</a></strong> to <a href='https://wandb.ai/mmser/av_hubert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mmser/av_hubert' target=\"_blank\">https://wandb.ai/mmser/av_hubert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mmser/av_hubert/runs/tshaz8f3' target=\"_blank\">https://wandb.ai/mmser/av_hubert/runs/tshaz8f3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses04M\n",
      "Train Samples: 3789\n",
      "Val Samples: 1264\n",
      "Test Samples: 478\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "sess_id = list(sess_dict.keys())[0]\n",
    "print(\"=\"*10, sess_id, \"=\"*10)\n",
    "\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 256, mmser_ds.df_[\"emotion_id\"].nunique())\n",
    "for param in avhubert_classifier.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "wandb.init()\n",
    "print(sess_id)\n",
    "train_set, val_set, test_set = build_ds(sess_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "341a9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=os.path.join(\"check_pts\", \"AVHUBERT\", sess_id, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\"))\n",
    "\n",
    "training_args = TrainingArguments(output_dir,report_to=\"wandb\")\n",
    "training_args.remove_unused_columns=False\n",
    "training_args.per_device_train_batch_size=6\n",
    "training_args.per_device_eval_batch_size=6\n",
    "training_args.logging_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "training_args.eval_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "training_args.evaluation_strategy=\"steps\" \n",
    "training_args.logging_strategy=\"steps\"\n",
    "training_args.load_best_model_at_end=True,\n",
    "training_args.save_strategy = \"no\"\n",
    "training_args.learning_rate=1e-3\n",
    "training_args.num_train_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27ade4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3160' max='3160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3160/3160 48:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wa</th>\n",
       "      <th>Ua</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.370700</td>\n",
       "      <td>1.388375</td>\n",
       "      <td>0.279272</td>\n",
       "      <td>0.297870</td>\n",
       "      <td>0.199164</td>\n",
       "      <td>0.279272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>1.347800</td>\n",
       "      <td>1.360365</td>\n",
       "      <td>0.378956</td>\n",
       "      <td>0.316246</td>\n",
       "      <td>0.284410</td>\n",
       "      <td>0.378956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>1.343300</td>\n",
       "      <td>1.349987</td>\n",
       "      <td>0.371044</td>\n",
       "      <td>0.307841</td>\n",
       "      <td>0.280109</td>\n",
       "      <td>0.371044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>1.344100</td>\n",
       "      <td>1.346372</td>\n",
       "      <td>0.327532</td>\n",
       "      <td>0.281593</td>\n",
       "      <td>0.218856</td>\n",
       "      <td>0.327532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.329700</td>\n",
       "      <td>1.332578</td>\n",
       "      <td>0.369462</td>\n",
       "      <td>0.309633</td>\n",
       "      <td>0.281683</td>\n",
       "      <td>0.369462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>1.309800</td>\n",
       "      <td>1.307625</td>\n",
       "      <td>0.356013</td>\n",
       "      <td>0.300167</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.356013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1162</td>\n",
       "      <td>1.280600</td>\n",
       "      <td>1.320493</td>\n",
       "      <td>0.339399</td>\n",
       "      <td>0.297829</td>\n",
       "      <td>0.290282</td>\n",
       "      <td>0.339399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1328</td>\n",
       "      <td>1.267200</td>\n",
       "      <td>1.347842</td>\n",
       "      <td>0.360759</td>\n",
       "      <td>0.348469</td>\n",
       "      <td>0.289072</td>\n",
       "      <td>0.360759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1494</td>\n",
       "      <td>1.256400</td>\n",
       "      <td>1.273257</td>\n",
       "      <td>0.401899</td>\n",
       "      <td>0.385834</td>\n",
       "      <td>0.356031</td>\n",
       "      <td>0.401899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>1.216400</td>\n",
       "      <td>1.238915</td>\n",
       "      <td>0.422468</td>\n",
       "      <td>0.408875</td>\n",
       "      <td>0.375707</td>\n",
       "      <td>0.422468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1826</td>\n",
       "      <td>1.203200</td>\n",
       "      <td>1.231967</td>\n",
       "      <td>0.434335</td>\n",
       "      <td>0.408581</td>\n",
       "      <td>0.389417</td>\n",
       "      <td>0.434335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992</td>\n",
       "      <td>1.145400</td>\n",
       "      <td>1.187440</td>\n",
       "      <td>0.480222</td>\n",
       "      <td>0.441790</td>\n",
       "      <td>0.434533</td>\n",
       "      <td>0.480222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2158</td>\n",
       "      <td>1.141300</td>\n",
       "      <td>1.136878</td>\n",
       "      <td>0.513449</td>\n",
       "      <td>0.485763</td>\n",
       "      <td>0.462588</td>\n",
       "      <td>0.513449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2324</td>\n",
       "      <td>1.061000</td>\n",
       "      <td>1.105552</td>\n",
       "      <td>0.553006</td>\n",
       "      <td>0.535867</td>\n",
       "      <td>0.543608</td>\n",
       "      <td>0.553006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>1.000100</td>\n",
       "      <td>1.043111</td>\n",
       "      <td>0.564873</td>\n",
       "      <td>0.557539</td>\n",
       "      <td>0.564468</td>\n",
       "      <td>0.564873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2656</td>\n",
       "      <td>0.902900</td>\n",
       "      <td>1.015458</td>\n",
       "      <td>0.593354</td>\n",
       "      <td>0.584887</td>\n",
       "      <td>0.590283</td>\n",
       "      <td>0.593354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2822</td>\n",
       "      <td>0.925400</td>\n",
       "      <td>0.946688</td>\n",
       "      <td>0.611551</td>\n",
       "      <td>0.613890</td>\n",
       "      <td>0.610712</td>\n",
       "      <td>0.611551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2988</td>\n",
       "      <td>0.828200</td>\n",
       "      <td>0.947052</td>\n",
       "      <td>0.628956</td>\n",
       "      <td>0.634159</td>\n",
       "      <td>0.625114</td>\n",
       "      <td>0.628956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3154</td>\n",
       "      <td>0.827400</td>\n",
       "      <td>0.940632</td>\n",
       "      <td>0.628956</td>\n",
       "      <td>0.629222</td>\n",
       "      <td>0.624583</td>\n",
       "      <td>0.628956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/multi_modal_ser/finetune_encoder/audio_video/avhubert_trainer.py:34: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_f1 = load_metric(\"f1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3160, training_loss=1.1628738169428667, metrics={'train_runtime': 2911.4976, 'train_samples_per_second': 13.014, 'train_steps_per_second': 1.085, 'total_flos': 0.0, 'train_loss': 1.1628738169428667, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from avhubert_trainer import CustomTrainer , compute_metrics\n",
    "avhubert_classifier = avhubert_classifier.to(device)\n",
    "trainer = CustomTrainer(\n",
    "    model=avhubert_classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f342fd-5ad9-47c6-9858-1b6b721a1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73117560-10f3-484d-813e-af68d15761cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637dacb6-d395-47e6-9b47-0c3f2a89d490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86cada-d000-4da5-bff4-09d1a5254029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ef31267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "test_result = trainer.predict(test_set).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "399ca56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.942188024520874, 'eval_wa': 0.6281645569620253, 'eval_ua': 0.6270679207630752, 'eval_f1': 0.6236114042374725, 'eval_accuracy': 0.6281645569620253, 'eval_runtime': 33.1998, 'eval_samples_per_second': 38.073, 'eval_steps_per_second': 3.193, 'epoch': 10.0}\n",
      "{'test_loss': 1.5278090238571167, 'test_wa': 0.37656903765690375, 'test_ua': 0.38682922402841513, 'test_f1': 0.3749555329414529, 'test_accuracy': 0.37656903765690375, 'test_runtime': 13.1598, 'test_samples_per_second': 36.323, 'test_steps_per_second': 3.04}\n"
     ]
    }
   ],
   "source": [
    "FREEZE_PROJ_PATH = \"/home/freeze/{}/projector\".format(sess_id)\n",
    "FREEZE_CLAS_PATH = \"/home/freeze/{}/classifier\".format(sess_id)\n",
    "os.makedirs(FREEZE_PROJ_PATH, exist_ok=True)\n",
    "os.makedirs(FREEZE_CLAS_PATH, exist_ok=True)\n",
    "\n",
    "FREEZE_PROJ = os.path.join(FREEZE_PROJ_PATH, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\")+\".pt\")\n",
    "FREEZE_CLAS = os.path.join(FREEZE_CLAS_PATH, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\")+\".pt\")\n",
    "\n",
    "torch.save(avhubert_classifier.projector.state_dict(), FREEZE_PROJ)\n",
    "torch.save(avhubert_classifier.classifier.state_dict(), FREEZE_CLAS)\n",
    "\n",
    "avhubert_classifier.projector.load_state_dict(torch.load(FREEZE_PROJ))\n",
    "avhubert_classifier.classifier.load_state_dict(torch.load(FREEZE_CLAS))\n",
    "\n",
    "print(eval_result)\n",
    "print(test_result)\n",
    "\n",
    "json_test = json.dumps(test_result, indent=4)\n",
    "json_eval = json.dumps(eval_result, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(\"{}_eval.json\".format(sess_id), \"w\") as outfile:\n",
    "    outfile.write(json_eval)\n",
    "with open(\"{}_test.json\".format(sess_id), \"w\") as outfile:\n",
    "    outfile.write(json_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163a9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00358b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967ebfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
