{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d4075b",
   "metadata": {},
   "source": [
    "### Prepare Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "041460cc-7376-4d29-b95d-156e4b21b530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install omegaconf==2.1.1\n",
    "# !pip install hydra-core==1.1.1\n",
    "# !pip install -U numpy==1.23.5\n",
    "# !apt-get update && apt-get install -y python3-opencv\n",
    "# !pip install opencv-python\n",
    "# !pip install scikit-image \n",
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install transformers[torch]\n",
    "# !pip install accelerate -U\n",
    "# !pip install wandb\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6c4388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'av_hubert'...\n",
      "remote: Enumerating objects: 149, done.\u001b[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 149 (delta 18), reused 22 (delta 14), pack-reused 111\u001b[K\n",
      "Receiving objects: 100% (149/149), 4.65 MiB | 8.29 MiB/s, done.\n",
      "Resolving deltas: 100% (64/64), done.\n",
      "/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert\n",
      "Submodule 'fairseq' (https://github.com/pytorch/fairseq) registered for path 'fairseq'\n",
      "Cloning into '/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq'...\n",
      "Submodule path 'fairseq': checked out 'afc77bdf4bb51453ce76f1572ef2ee6ddcda8eeb'\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.23.5)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: python_speech_features in /opt/conda/lib/python3.10/site-packages (0.6)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-video in /opt/conda/lib/python3.10/site-packages (1.1.11)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from scikit-video) (1.23.5)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from scikit-video) (10.0.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from scikit-video) (1.11.3)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq\n",
      "Processing /home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/fairseq\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (1.15.1)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (3.0.4)\n",
      "Requirement already satisfied: hydra-core<1.1 in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (1.0.7)\n",
      "Requirement already satisfied: omegaconf<2.1 in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (2.0.6)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (2023.10.3)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (2.3.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (4.65.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq==1.0.0a0+afc77bd) (1.23.5)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.10/site-packages (from hydra-core<1.1->fairseq==1.0.0a0+afc77bd) (4.8)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (4.7.1)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (4.9.3)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq==1.0.0a0+afc77bd) (2.21)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+afc77bd) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->fairseq==1.0.0a0+afc77bd) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->fairseq==1.0.0a0+afc77bd) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fairseq==1.0.0a0+afc77bd) (1.3.0)\n",
      "Building wheels for collected packages: fairseq\n",
      "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-1.0.0a0+afc77bd-cp310-cp310-linux_x86_64.whl size=1596737 sha256=9cb37e7bd4ff409839241cab239589d6c107cabb3681455ef89076c96ea4715c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zn0t7ohp/wheels/27/2e/27/5adef5395082fdea035775c3b2a2ba250cec710d39b3beccd6\n",
      "Successfully built fairseq\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: fairseq\n",
      "  Attempting uninstall: fairseq\n",
      "    Found existing installation: fairseq 1.0.0a0+afc77bd\n",
      "    Uninstalling fairseq-1.0.0a0+afc77bd:\n",
      "      Successfully uninstalled fairseq-1.0.0a0+afc77bd\n",
      "Successfully installed fairseq-1.0.0a0+afc77bd\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/av_hubert.git\n",
    "\n",
    "%cd av_hubert\n",
    "!git submodule init\n",
    "!git submodule update\n",
    "!pip install scipy\n",
    "!pip install sentencepiece\n",
    "!pip install python_speech_features\n",
    "!pip install scikit-video\n",
    "\n",
    "%cd fairseq\n",
    "!pip install ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e231ede0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert\n",
      "3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "import cv2\n",
    "import tempfile\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import sys\n",
    "sys.path.append(\"/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\")\n",
    "%cd /home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/\n",
    "import utils as avhubert_utils\n",
    "from argparse import Namespace\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.version)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128ecb29-946d-4fae-b806-17946ca63f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Tue Oct 24 11:51:23 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   32C    P8              15W / 450W |      5MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:03:00.0 Off |                  Off |\n",
      "|  0%   28C    P8               9W / 450W |      5MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1442ff",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15addb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"/home/check_pts/\")\n",
    "# # !wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/vsr/base_vox_433h.pt -O /home/check_pts/avhubert.pt\n",
    "# !wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/clean-pretrain/base_vox_iter4.pt -O /home/check_pts/avhubert.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edf8e1",
   "metadata": {},
   "source": [
    "### Build Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da14d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: pre-trained w/o fine-tuning\n"
     ]
    }
   ],
   "source": [
    "user_dir = \"/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"/home/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7d434",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86df1ecf-343d-4464-824b-4adf070a8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e339c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_ds import AVHUBERTDataset\n",
    "mmser_ds = torch.load(\"/home/avhubert_ds2.pt\")\n",
    "mmser_ds.video_path = \"/home/face_raw/\"\n",
    "\n",
    "# outputs = model.extract_finetune(mmser_ds[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4043f023-01f6-4abc-aa9d-665b1ee7fbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5531/5531 [03:38<00:00, 25.35it/s]\n"
     ]
    }
   ],
   "source": [
    "mmser_ds.cached = False\n",
    "mmser_ds.__cache__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb06072",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9da70288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_classifier import AVHUBERTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "95d16866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = AVHUBERTClassifier(model, 768, 256, mmser_ds.df_[\"emotion_id\"].nunique())\n",
    "# classifier(**mmser_ds[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d940a",
   "metadata": {},
   "source": [
    "### Build Train Test DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c429bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_ = mmser_ds.df_\n",
    "mmser_ds.df_[\"bigsess\"] = mmser_ds.df_[\"session\"].apply(lambda x: x[:-1])\n",
    "sess_dict = mmser_ds.df_.groupby(\"bigsess\").groups\n",
    "all_indices = set(mmser_ds.df_.index.tolist())\n",
    "\n",
    "sess_ds = {}\n",
    "for i in range(1,6):\n",
    "    sess = \"Ses0{}\".format(i)\n",
    "    sess_val = \"Ses0{}\".format(i%5+1)\n",
    "    sess_ds[sess+\"_test\"] = Subset(mmser_ds, \n",
    "                                    indices=sess_dict[sess])\n",
    "    # sess_ds[sess+\"_val\"] = Subset(mmser_ds, \n",
    "    #                                 indices=sess_dict[sess_val])\n",
    "    sess_ds[sess+\"_train\"] = Subset(mmser_ds, \n",
    "                                    indices=list(all_indices-set(sess_dict[sess])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eadf7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ds(sess_id):\n",
    "    train_size = int(len(sess_ds[sess_id+\"_train\"])*0.8)\n",
    "    val_size = len(sess_ds[sess_id+\"_train\"])-train_size\n",
    "    train_set, val_set = torch.utils.data.random_split(sess_ds[sess_id+\"_train\"], [train_size, val_size])\n",
    "    test_set = sess_ds[sess_id+\"_test\"]\n",
    "    # train_set = sess_ds[sess_id+\"_train\"]\n",
    "    # val_set = sess_ds[sess_id+\"_val\"]\n",
    "\n",
    "    print(\"Train Samples:\", len(train_set))\n",
    "    print(\"Val Samples:\", len(val_set))\n",
    "    print(\"Test Samples:\", len(test_set))\n",
    "    \n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573929b",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be847c2-4282-4906-8add-40136adb8012",
   "metadata": {},
   "source": [
    "API: 2999b8f99f0f62b4f64c48a1c8be9a16945183e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2329893c-3888-4ff6-b37e-b1b538afb36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: pre-trained w/o fine-tuning\n"
     ]
    }
   ],
   "source": [
    "user_dir = \"/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/avhubert\"\n",
    "utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "ckpt_path = \"/home/check_pts/avhubert.pt\"\n",
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])  \n",
    "model = models[0]\n",
    "if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ecfde834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Ses01 ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5npj3itu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5bb1685c41404fa6c3c76a2bb1242c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▃▇▂▁▂▂▂▁▂▂▂</td></tr><tr><td>eval/f1</td><td>█▃▆▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/loss</td><td>▁█▂▅▅▅▅▅▅▅▅▅</td></tr><tr><td>eval/runtime</td><td>▁▇▂▅▄▁▂▄▃▆▂█</td></tr><tr><td>eval/samples_per_second</td><td>█▂▇▄▅█▇▅▆▃▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▂▇▄▅█▇▅▆▃▇▁</td></tr><tr><td>eval/ua</td><td>█▂▆▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/wa</td><td>█▃▇▂▁▂▂▂▁▂▂▂</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇█</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▅▅▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>▇▁▇▄██▇▇██▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.31573</td></tr><tr><td>eval/f1</td><td>0.15153</td></tr><tr><td>eval/loss</td><td>1.36241</td></tr><tr><td>eval/runtime</td><td>18.1037</td></tr><tr><td>eval/samples_per_second</td><td>49.161</td></tr><tr><td>eval/steps_per_second</td><td>4.143</td></tr><tr><td>eval/ua</td><td>0.25</td></tr><tr><td>eval/wa</td><td>0.31573</td></tr><tr><td>train/epoch</td><td>7.27</td></tr><tr><td>train/global_step</td><td>2158</td></tr><tr><td>train/learning_rate</td><td>0.00258</td></tr><tr><td>train/loss</td><td>1.3599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fallen-puddle-3</strong> at: <a href='https://wandb.ai/mmser/av_hubert/runs/5npj3itu' target=\"_blank\">https://wandb.ai/mmser/av_hubert/runs/5npj3itu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231024_132908-5npj3itu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5npj3itu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e44902b0428413ca230e4c6a3cf5248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112358374521136, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/multi_modal_ser/finetune_encoder/audio_video/av_hubert/wandb/run-20231024_135118-maxl3al3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mmser/av_hubert/runs/maxl3al3' target=\"_blank\">eternal-plasma-4</a></strong> to <a href='https://wandb.ai/mmser/av_hubert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mmser/av_hubert' target=\"_blank\">https://wandb.ai/mmser/av_hubert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mmser/av_hubert/runs/maxl3al3' target=\"_blank\">https://wandb.ai/mmser/av_hubert/runs/maxl3al3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses01\n",
      "Train Samples: 3556\n",
      "Val Samples: 890\n",
      "Test Samples: 1085\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "sess_id = list(sess_dict.keys())[0]\n",
    "print(\"=\"*10, sess_id, \"=\"*10)\n",
    "\n",
    "avhubert_classifier = AVHUBERTClassifier(model, 768, 256, mmser_ds.df_[\"emotion_id\"].nunique())\n",
    "for param in avhubert_classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "wandb.init()\n",
    "print(sess_id)\n",
    "train_set, val_set, test_set = build_ds(sess_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "341a9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=os.path.join(\"check_pts\", \"AVHUBERT\", sess_id, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\"))\n",
    "\n",
    "training_args = TrainingArguments(output_dir,report_to=\"wandb\")\n",
    "training_args.remove_unused_columns=False\n",
    "training_args.per_device_train_batch_size=6\n",
    "training_args.per_device_eval_batch_size=6\n",
    "training_args.logging_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "training_args.eval_steps = int(1000/training_args.per_device_train_batch_size)\n",
    "training_args.evaluation_strategy=\"steps\" \n",
    "training_args.logging_strategy=\"steps\"\n",
    "training_args.load_best_model_at_end=True,\n",
    "training_args.save_strategy = \"no\"\n",
    "training_args.learning_rate=5e-3\n",
    "training_args.num_train_epochs=15\n",
    "training_args.metric_for_best_model = 'loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "27ade4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avhubert_trainer import CustomTrainer , compute_metrics\n",
    "from transformers import EarlyStoppingCallback, TrainerCallback, TrainerState\n",
    "\n",
    "avhubert_classifier = avhubert_classifier.to(device)\n",
    "trainer = CustomTrainer(\n",
    "    model=avhubert_classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6778b05-02f5-4598-86ed-2a69d88a1323",
   "metadata": {},
   "source": [
    "##### Gradual Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c7a1b316-8b55-4e88-bbf0-32e4d8e271dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreezingCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, freeze_encoder_epochs: int):\n",
    "        self.freeze_encoder_epochs = freeze_encoder_epochs\n",
    "\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        print(state.epoch, self.freeze_encoder_epochs)\n",
    "        model = kwargs[\"model\"]\n",
    "        if state.epoch >= self.freeze_encoder_epochs:\n",
    "            print(\"=\"*10, \"Freezing\", \"=\"*10)\n",
    "            for param in model.encoder.feature_extractor_video.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        model = kwargs[\"model\"]\n",
    "        for name, param in model.named_parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "90bf04a5-0861-4dba-917b-3a23fdfff97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freezing_callback = FreezingCallback(5)\n",
    "trainer.add_callback(freezing_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f342fd-5ad9-47c6-9858-1b6b721a1f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1637' max='4455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1637/4455 15:42 < 27:03, 1.74 it/s, Epoch 5.51/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wa</th>\n",
       "      <th>Ua</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.226000</td>\n",
       "      <td>1.174462</td>\n",
       "      <td>0.467416</td>\n",
       "      <td>0.432880</td>\n",
       "      <td>0.423563</td>\n",
       "      <td>0.467416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>1.194400</td>\n",
       "      <td>1.160704</td>\n",
       "      <td>0.461798</td>\n",
       "      <td>0.435711</td>\n",
       "      <td>0.453494</td>\n",
       "      <td>0.461798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>1.216100</td>\n",
       "      <td>1.177264</td>\n",
       "      <td>0.434831</td>\n",
       "      <td>0.402085</td>\n",
       "      <td>0.373170</td>\n",
       "      <td>0.434831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>1.217000</td>\n",
       "      <td>1.146338</td>\n",
       "      <td>0.488764</td>\n",
       "      <td>0.477488</td>\n",
       "      <td>0.477150</td>\n",
       "      <td>0.488764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.189500</td>\n",
       "      <td>1.138939</td>\n",
       "      <td>0.467416</td>\n",
       "      <td>0.469305</td>\n",
       "      <td>0.459201</td>\n",
       "      <td>0.467416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>1.181400</td>\n",
       "      <td>1.139251</td>\n",
       "      <td>0.484270</td>\n",
       "      <td>0.446065</td>\n",
       "      <td>0.439037</td>\n",
       "      <td>0.484270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1162</td>\n",
       "      <td>1.206200</td>\n",
       "      <td>1.165566</td>\n",
       "      <td>0.462921</td>\n",
       "      <td>0.440203</td>\n",
       "      <td>0.423509</td>\n",
       "      <td>0.462921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1328</td>\n",
       "      <td>1.188700</td>\n",
       "      <td>1.145339</td>\n",
       "      <td>0.470787</td>\n",
       "      <td>0.446933</td>\n",
       "      <td>0.420578</td>\n",
       "      <td>0.470787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1494</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.155846</td>\n",
       "      <td>0.468539</td>\n",
       "      <td>0.431380</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.468539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 5\n",
      "2.0 5\n",
      "3.0 5\n",
      "4.0 5\n",
      "5.0 5\n",
      "========== Freezing ==========\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73117560-10f3-484d-813e-af68d15761cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53544a-76b0-4ab5-b22b-f4979adfa195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0829d84-db7b-46f5-9363-8cf7e5d57cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f2bba2c6-d14c-47b4-a81b-c4c56d3ef80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a86cada-d000-4da5-bff4-09d1a5254029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_preds = trainer.predict(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba7c74dd-72b3-46d4-8e41-94309b0d2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_labels = val_preds.predictions.argmax(axis=1)\n",
    "true_labels = val_preds.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3b34e23-f64d-41ff-83ba-c1117cdea3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 3 0]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels[10:15])\n",
    "print(true_labels[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84a1832c-d791-4271-8f75-b9370915e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e87d2156-d8b1-4b4e-821e-24a4e8df145d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78546713, 0.80825959, 0.75142315, 0.76785714])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true_labels, pred_labels, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c5d337-63ca-443f-95c1-759243d52539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a002797a-6c14-432d-b6a9-f73c393a7893",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [fn[\"fn\"] for fn in train_set]    \n",
    "val_ids = [fn[\"fn\"] for fn in val_set]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9caad23-71cd-42b8-94f6-7f0e5f66085b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_ids).intersection(set(val_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e45f2-a43c-4056-a049-2d527b979c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8ef31267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "test_result = trainer.predict(test_set).metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "40875ee9-9164-4545-b53f-dc2a9e210777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.121928095817566,\n",
       " 'test_wa': 0.46912442396313364,\n",
       " 'test_ua': 0.491775778649466,\n",
       " 'test_f1': 0.43331144715120545,\n",
       " 'test_accuracy': 0.46912442396313364,\n",
       " 'test_runtime': 21.4022,\n",
       " 'test_samples_per_second': 50.696,\n",
       " 'test_steps_per_second': 4.252}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83889a1d-fb15-4e01-9690-307e0650526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da509cb2-d2af-4235-b631-337cb7964263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ca56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_PROJ_PATH = \"/home/freeze/{}/projector\".format(sess_id)\n",
    "FREEZE_CLAS_PATH = \"/home/freeze/{}/classifier\".format(sess_id)\n",
    "os.makedirs(FREEZE_PROJ_PATH, exist_ok=True)\n",
    "os.makedirs(FREEZE_CLAS_PATH, exist_ok=True)\n",
    "\n",
    "FREEZE_PROJ = os.path.join(FREEZE_PROJ_PATH, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\")+\".pt\")\n",
    "FREEZE_CLAS = os.path.join(FREEZE_CLAS_PATH, datetime.datetime.now().date().strftime(format=\"%Y-%m-%d\")+\".pt\")\n",
    "\n",
    "torch.save(avhubert_classifier.projector.state_dict(), FREEZE_PROJ)\n",
    "torch.save(avhubert_classifier.classifier.state_dict(), FREEZE_CLAS)\n",
    "\n",
    "avhubert_classifier.projector.load_state_dict(torch.load(FREEZE_PROJ))\n",
    "avhubert_classifier.classifier.load_state_dict(torch.load(FREEZE_CLAS))\n",
    "\n",
    "print(eval_result)\n",
    "print(test_result)\n",
    "\n",
    "json_test = json.dumps(test_result, indent=4)\n",
    "json_eval = json.dumps(eval_result, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(\"{}_eval.json\".format(sess_id), \"w\") as outfile:\n",
    "    outfile.write(json_eval)\n",
    "with open(\"{}_test.json\".format(sess_id), \"w\") as outfile:\n",
    "    outfile.write(json_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163a9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00358b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967ebfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
